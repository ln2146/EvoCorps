#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Frontend API Server for EvoCorps
æä¾›å‰ç«¯æ‰€éœ€çš„æ•°æ®åº“æŸ¥è¯¢æ¥å£
"""

import sys
import io
import datetime
from typing import Optional, List, Dict

# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸º UTF-8 ç¼–ç 
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from flask import Flask, jsonify, request
from flask_cors import CORS
import sqlite3
import os
import glob
import subprocess
import signal
import psutil
import json
import time

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
src_path = os.path.join(os.path.dirname(__file__), 'src')
if src_path not in sys.path:
    sys.path.insert(0, src_path)

# å°è¯•å¯¼å…¥AIæ¨¡å‹ç›¸å…³æ¨¡å—
AI_AVAILABLE = False
try:
    from multi_model_selector import multi_model_selector
    from utils import Utils
    AI_AVAILABLE = True
    print("âœ… AIæ¨¡å‹æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ AIæ¨¡å‹æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    print("âš ï¸ é‡‡è®¿åŠŸèƒ½å°†ä½¿ç”¨ç®€åŒ–çš„æ¨¡æ¿å›ç­”")
    print("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")

app = Flask(__name__)
CORS(app)

DATABASE_DIR = 'database'
OPINION_BALANCE_LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs', 'opinion_balance')
WORKFLOW_LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs', 'workflow')


class ProcessManager:
    """ç®¡ç†æ¼”ç¤ºç³»ç»Ÿçš„æ‰€æœ‰è¿›ç¨‹"""
    
    def __init__(self):
        """åˆå§‹åŒ– ProcessManager
        
        åˆå§‹åŒ–è¿›ç¨‹å­—å…¸ã€ä¸´æ—¶æ–‡ä»¶åˆ—è¡¨å’Œ Python è§£é‡Šå™¨è·¯å¾„
        """
        self.processes = {
            'database': None,      # å­˜å‚¨è¿›ç¨‹ PID
            'main': None,
            'opinion_balance': None
        }
        self.temp_files = []       # ä¸´æ—¶æ–‡ä»¶åˆ—è¡¨ï¼Œç”¨äºæ¸…ç†
        self.python_exe = sys.executable  # å½“å‰ Python è§£é‡Šå™¨è·¯å¾„
        
        # å¯åŠ¨æ—¶æ¸…ç†æ‰€æœ‰æ—§çš„ä¸´æ—¶æ–‡ä»¶
        self._cleanup_all_temp_files()
    
    def _is_process_running(self, process_name: str) -> bool:
        """æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿è¡Œï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            process_name: è¿›ç¨‹åç§° ('database', 'main', 'opinion_balance')
            
        Returns:
            bool: è¿›ç¨‹æ˜¯å¦æ­£åœ¨è¿è¡Œ
        """
        # å¦‚æœæœ‰è®°å½•çš„è¿›ç¨‹ PID
        if self.processes.get(process_name):
            pid = self.processes[process_name]
            try:
                proc = psutil.Process(pid)
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»ä¸”å‘½ä»¤è¡ŒåŒ¹é…
                if proc.is_running():
                    cmdline = ' '.join(proc.cmdline())
                    # æ ¹æ®ä¸åŒè¿›ç¨‹æ£€æŸ¥ä¸åŒçš„å…³é”®å­—
                    keywords = {
                        'database': 'start_database_service.py',
                        'main': 'main.py',
                        'opinion_balance': 'opinion_balance_launcher.py'
                    }
                    if keywords[process_name] in cmdline:
                        return True
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # å¦‚æœæ²¡æœ‰è®°å½•ï¼Œæ‰«ææ‰€æœ‰è¿›ç¨‹
        keywords = {
            'database': 'start_database_service.py',
            'main': 'main.py',
            'opinion_balance': 'opinion_balance_launcher.py'
        }
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = proc.info.get('cmdline')
                if cmdline and any(keywords[process_name] in str(cmd) for cmd in cmdline):
                    self.processes[process_name] = proc.info['pid']
                    return True
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        return False
    
    def _create_auto_input_script(
        self, 
        script_path: str, 
        inputs: List[str],
        conda_env: Optional[str] = None
    ) -> str:
        """åˆ›å»ºè‡ªåŠ¨è¾“å…¥çš„æ‰¹å¤„ç†è„šæœ¬ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            script_path: è¦è¿è¡Œçš„ Python è„šæœ¬è·¯å¾„
            inputs: è¾“å…¥åºåˆ—åˆ—è¡¨
            conda_env: conda ç¯å¢ƒåç§°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            
        Returns:
            str: æ‰¹å¤„ç†æ–‡ä»¶è·¯å¾„
        """
        # ç”Ÿæˆå”¯ä¸€çš„ä¸´æ—¶æ‰¹å¤„ç†æ–‡ä»¶å
        timestamp = int(time.time())
        bat_file = f"temp_input_{timestamp}.bat"
        
        with open(bat_file, 'w', encoding='utf-8') as f:
            # ä¸éœ€è¦æ¿€æ´» conda ç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨
            # ä½¿ç”¨ sys.executable ç¡®ä¿ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨
            
            # å†™å…¥è‡ªåŠ¨è¾“å…¥å‘½ä»¤
            f.write('@echo off\n')
            f.write('(\n')
            for inp in inputs:
                if inp == '':  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºå›è½¦
                    f.write('echo.\n')
                else:
                    f.write(f'echo {inp}\n')
            f.write(f') | "{self.python_exe}" {script_path}\n')
            # æ·»åŠ  exit å‘½ä»¤ï¼Œç¡®ä¿æ‰¹å¤„ç†æ‰§è¡Œå®Œæ¯•åç«‹å³é€€å‡ºï¼Œä¸æ˜¾ç¤ºä»»ä½•æç¤º
            f.write('exit\n')
        
        # è®°å½•ä¸´æ—¶æ–‡ä»¶è·¯å¾„ç”¨äºåç»­æ¸…ç†
        self.temp_files.append(bat_file)
        return bat_file
    
    def _start_process_in_terminal(
        self, 
        script_path: str, 
        title: str,
        auto_inputs: Optional[List[str]] = None,
        conda_env: Optional[str] = None
    ) -> subprocess.Popen:
        """åœ¨æ–°ç»ˆç«¯å¯åŠ¨è¿›ç¨‹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            script_path: è¦è¿è¡Œçš„ Python è„šæœ¬è·¯å¾„
            title: ç»ˆç«¯çª—å£æ ‡é¢˜
            auto_inputs: è‡ªåŠ¨è¾“å…¥åºåˆ—ï¼ˆå¯é€‰ï¼‰
            conda_env: conda ç¯å¢ƒåç§°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            
        Returns:
            subprocess.Popen: è¿›ç¨‹å¯¹è±¡
        """
        if auto_inputs:
            # åˆ›å»ºä¸´æ—¶æ‰¹å¤„ç†æ–‡ä»¶ï¼ˆåŒ…å« exit å‘½ä»¤ï¼‰
            bat_file = self._create_auto_input_script(script_path, auto_inputs, conda_env)
            # ç›´æ¥å¯åŠ¨æ‰¹å¤„ç†æ–‡ä»¶
            cmd = f'cmd /c start "{title}" cmd /c "{bat_file}"'
        else:
            # ç›´æ¥å¯åŠ¨ï¼Œä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨
            cmd = f'cmd /c start "{title}" cmd /c ""{self.python_exe}" {script_path} & exit"'
        
        process = subprocess.Popen(cmd, shell=True)
        return process
    
    def _cleanup_temp_files(self):
        """æ¸…ç†è®°å½•çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        for temp_file in self.temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except (FileNotFoundError, PermissionError) as e:
                # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æ¸…ç†è¿‡ç¨‹
                print(f"è­¦å‘Š: æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {temp_file}: {e}")
        
        # æ¸…ç©ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        self.temp_files = []
    
    def _cleanup_all_temp_files(self):
        """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ‰¹å¤„ç†æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        æ‰«æå½“å‰ç›®å½•ï¼Œåˆ é™¤æ‰€æœ‰ temp_input_*.bat æ–‡ä»¶
        """
        try:
            import glob
            # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„ä¸´æ—¶æ–‡ä»¶
            temp_files = glob.glob('temp_input_*.bat')
            
            for temp_file in temp_files:
                try:
                    os.remove(temp_file)
                    print(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                except (FileNotFoundError, PermissionError) as e:
                    # æ–‡ä»¶å¯èƒ½æ­£åœ¨ä½¿ç”¨æˆ–å·²è¢«åˆ é™¤
                    pass
        except Exception as e:
            # æ¸…ç†å¤±è´¥ä¸åº”å½±å“ç¨‹åºè¿è¡Œ
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def start_demo(self, conda_env: Optional[str] = None) -> dict:
        """å¯åŠ¨æ¼”ç¤ºï¼ˆæ•°æ®åº“ + ä¸»ç¨‹åºï¼‰
        
        æ³¨æ„: conda_env å‚æ•°å·²åºŸå¼ƒï¼Œç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨å½“å‰ Python ç¯å¢ƒ
        
        Args:
            conda_env: conda ç¯å¢ƒåç§°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            
        Returns:
            dict: å¯åŠ¨ç»“æœ
        """
        try:
            # æ¸…ç†æ—§çš„ä¸´æ—¶æ–‡ä»¶
            self._cleanup_all_temp_files()
            
            # æ£€æŸ¥æ•°æ®åº“å’Œä¸»ç¨‹åºæ˜¯å¦å·²è¿è¡Œ
            if self._is_process_running('database'):
                return {
                    'success': False,
                    'message': 'Database service is already running',
                    'error': 'ProcessAlreadyRunning'
                }
            
            if self._is_process_running('main'):
                return {
                    'success': False,
                    'message': 'Main program is already running',
                    'error': 'ProcessAlreadyRunning'
                }
            
            # å¯åŠ¨æ•°æ®åº“æœåŠ¡
            db_script = 'src/start_database_service.py'
            if not os.path.exists(db_script):
                return {
                    'success': False,
                    'message': f'Database script not found: {db_script}',
                    'error': 'FileNotFound'
                }
            
            db_process = self._start_process_in_terminal(
                script_path=db_script,
                title='EvoCorps-Database',
                auto_inputs=None,
                conda_env=conda_env
            )
            
            # è®°å½•æ•°æ®åº“è¿›ç¨‹ï¼ˆæ³¨æ„ï¼šç”±äºæ˜¯åœ¨æ–°ç»ˆç«¯å¯åŠ¨ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è·å–å­è¿›ç¨‹çš„ PIDï¼‰
            # æˆ‘ä»¬éœ€è¦ç­‰å¾…è¿›ç¨‹å¯åŠ¨åé€šè¿‡ _is_process_running æ¥è·å– PID
            time.sleep(2)  # ç­‰å¾…è¿›ç¨‹å¯åŠ¨
            
            # å°è¯•è·å–æ•°æ®åº“è¿›ç¨‹ PID
            db_pid = None
            if self._is_process_running('database'):
                db_pid = self.processes.get('database')
            
            # ç­‰å¾… 5 ç§’è®©æ•°æ®åº“åˆå§‹åŒ–
            print("ç­‰å¾…æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–...")
            time.sleep(5)
            
            # åˆ›å»ºè‡ªåŠ¨è¾“å…¥è„šæœ¬å¹¶å¯åŠ¨ä¸»ç¨‹åº
            main_script = 'src/main.py'
            if not os.path.exists(main_script):
                return {
                    'success': False,
                    'message': f'Main script not found: {main_script}',
                    'error': 'FileNotFound'
                }
            
            # è¾“å…¥åºåˆ—ï¼šn, y, n, n, Enter
            auto_inputs = ['n', 'y', 'n', 'n', '']
            
            main_process = self._start_process_in_terminal(
                script_path=main_script,
                title='EvoCorps-Main',
                auto_inputs=auto_inputs,
                conda_env=conda_env
            )
            
            # ç­‰å¾…ä¸»ç¨‹åºå¯åŠ¨
            time.sleep(2)
            
            # å°è¯•è·å–ä¸»ç¨‹åºè¿›ç¨‹ PID
            main_pid = None
            if self._is_process_running('main'):
                main_pid = self.processes.get('main')
            
            return {
                'success': True,
                'message': 'Dynamic demo started successfully',
                'processes': {
                    'database': {
                        'pid': db_pid,
                        'status': 'running' if db_pid else 'starting'
                    },
                    'main': {
                        'pid': main_pid,
                        'status': 'running' if main_pid else 'starting'
                    }
                }
            }
            
        except FileNotFoundError as e:
            return {
                'success': False,
                'message': f'Script not found: {str(e)}',
                'error': 'FileNotFound'
            }
        except PermissionError as e:
            return {
                'success': False,
                'message': f'Permission denied: {str(e)}',
                'error': 'PermissionDenied'
            }
        except Exception as e:
            return {
                'success': False,
                'message': f'Failed to start demo: {str(e)}',
                'error': 'ProcessStartFailed'
            }
    
    def stop_all_processes(self) -> dict:
        """åœæ­¢æ‰€æœ‰è¿›ç¨‹
        
        éå†æ‰€æœ‰å·²è®°å½•çš„è¿›ç¨‹ï¼Œä½¿ç”¨ psutil.Process.terminate() ä¼˜é›…å…³é—­ï¼Œ
        ç­‰å¾… 3 ç§’åæ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç»ˆæ­¢ï¼Œå¯¹æœªç»ˆæ­¢çš„è¿›ç¨‹ä½¿ç”¨ kill() å¼ºåˆ¶å…³é—­ã€‚
        æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œé‡ç½®è¿›ç¨‹è®°å½•å­—å…¸ã€‚
        
        Returns:
            dict: åœæ­¢ç»“æœï¼ˆåŒ…å«å·²åœæ­¢è¿›ç¨‹åˆ—è¡¨å’Œé”™è¯¯ä¿¡æ¯ï¼‰
        """
        stopped = []
        errors = []
        
        for name, pid in self.processes.items():
            if pid is None:
                continue
                
            try:
                proc = psutil.Process(pid)
                
                # è·å–çˆ¶è¿›ç¨‹ï¼ˆé€šå¸¸æ˜¯ cmd.exeï¼‰
                try:
                    parent = proc.parent()
                    parent_pid = parent.pid if parent else None
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    parent_pid = None
                
                # 1. å°è¯•ä¼˜é›…å…³é—­ Python è¿›ç¨‹
                proc.terminate()
                
                # 2. ç­‰å¾…æœ€å¤š 3 ç§’
                try:
                    proc.wait(timeout=3)
                    stopped.append(name)
                except psutil.TimeoutExpired:
                    # 3. å¼ºåˆ¶å…³é—­ Python è¿›ç¨‹
                    proc.kill()
                    proc.wait(timeout=1)
                    stopped.append(name)
                
                # 4. å¦‚æœæœ‰çˆ¶è¿›ç¨‹ï¼ˆcmd.exeï¼‰ï¼Œä¹Ÿå…³é—­å®ƒä»¥å…³é—­ç»ˆç«¯çª—å£
                if parent_pid:
                    try:
                        parent_proc = psutil.Process(parent_pid)
                        # æ£€æŸ¥çˆ¶è¿›ç¨‹æ˜¯å¦æ˜¯ cmd.exe
                        if 'cmd.exe' in parent_proc.name().lower():
                            parent_proc.terminate()
                            try:
                                parent_proc.wait(timeout=2)
                            except psutil.TimeoutExpired:
                                parent_proc.kill()
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        pass  # çˆ¶è¿›ç¨‹å¯èƒ½å·²ç»å…³é—­
                    
            except psutil.NoSuchProcess:
                # è¿›ç¨‹å·²ç»ä¸å­˜åœ¨
                stopped.append(name)
            except Exception as e:
                errors.append(f"{name}: {str(e)}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self._cleanup_temp_files()
        self._cleanup_all_temp_files()  # é¢å¤–æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
        
        # é‡ç½®è¿›ç¨‹è®°å½•
        self.processes = {k: None for k in self.processes}
        
        return {
            'success': len(errors) == 0,
            'message': 'All processes stopped' if not errors else 'Some processes failed to stop',
            'stopped_processes': stopped,
            'errors': errors
        }
    
    def start_opinion_balance(self, conda_env: Optional[str] = None) -> dict:
        """å¯åŠ¨èˆ†è®ºå¹³è¡¡ç³»ç»Ÿ
        
        æ³¨æ„: conda_env å‚æ•°å·²åºŸå¼ƒï¼Œç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨å½“å‰ Python ç¯å¢ƒ
        
        Args:
            conda_env: conda ç¯å¢ƒåç§°ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            
        Returns:
            dict: å¯åŠ¨ç»“æœ
        """
        try:
            # æ¸…ç†æ—§çš„ä¸´æ—¶æ–‡ä»¶
            self._cleanup_all_temp_files()
            
            # æ£€æŸ¥èˆ†è®ºå¹³è¡¡è¿›ç¨‹æ˜¯å¦å·²è¿è¡Œ
            if self._is_process_running('opinion_balance'):
                return {
                    'success': False,
                    'message': 'Opinion balance system is already running',
                    'error': 'ProcessAlreadyRunning'
                }
            
            # å¯åŠ¨èˆ†è®ºå¹³è¡¡å¯åŠ¨å™¨
            ob_script = 'src/opinion_balance_launcher.py'
            if not os.path.exists(ob_script):
                return {
                    'success': False,
                    'message': f'Opinion balance script not found: {ob_script}',
                    'error': 'FileNotFound'
                }
            
            # åˆ›å»ºè‡ªåŠ¨è¾“å…¥è„šæœ¬ï¼ˆè¾“å…¥åºåˆ—ï¼šstart, auto-statusï¼‰
            auto_inputs = ['start', 'auto-status']
            
            ob_process = self._start_process_in_terminal(
                script_path=ob_script,
                title='EvoCorps-OpinionBalance',
                auto_inputs=auto_inputs,
                conda_env=conda_env
            )
            
            # ç­‰å¾…è¿›ç¨‹å¯åŠ¨
            time.sleep(2)
            
            # å°è¯•è·å–è¿›ç¨‹ PID
            ob_pid = None
            if self._is_process_running('opinion_balance'):
                ob_pid = self.processes.get('opinion_balance')
            
            return {
                'success': True,
                'message': 'Opinion balance system started',
                'process': {
                    'pid': ob_pid,
                    'status': 'running' if ob_pid else 'starting'
                }
            }
            
        except FileNotFoundError as e:
            return {
                'success': False,
                'message': f'Script not found: {str(e)}',
                'error': 'FileNotFound'
            }
        except PermissionError as e:
            return {
                'success': False,
                'message': f'Permission denied: {str(e)}',
                'error': 'PermissionDenied'
            }
        except Exception as e:
            return {
                'success': False,
                'message': f'Failed to start opinion balance: {str(e)}',
                'error': 'ProcessStartFailed'
            }
    
    def stop_process(self, process_name: str) -> dict:
        """åœæ­¢å•ä¸ªè¿›ç¨‹
        
        Args:
            process_name: è¿›ç¨‹åç§° ('database', 'main', 'opinion_balance')
            
        Returns:
            dict: åœæ­¢ç»“æœ
        """
        if process_name not in self.processes:
            return {
                'success': False,
                'message': f'Unknown process name: {process_name}',
                'error': 'InvalidProcessName'
            }
        
        pid = self.processes.get(process_name)
        
        if pid is None:
            return {
                'success': False,
                'message': f'{process_name} is not running',
                'error': 'ProcessNotRunning'
            }
        
        try:
            proc = psutil.Process(pid)
            
            # è·å–çˆ¶è¿›ç¨‹ï¼ˆé€šå¸¸æ˜¯ cmd.exeï¼‰
            try:
                parent = proc.parent()
                parent_pid = parent.pid if parent else None
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                parent_pid = None
            
            # 1. å°è¯•ä¼˜é›…å…³é—­ Python è¿›ç¨‹
            proc.terminate()
            
            # 2. ç­‰å¾…æœ€å¤š 3 ç§’
            try:
                proc.wait(timeout=3)
            except psutil.TimeoutExpired:
                # 3. å¼ºåˆ¶å…³é—­ Python è¿›ç¨‹
                proc.kill()
                proc.wait(timeout=1)
            
            # 4. å¦‚æœæœ‰çˆ¶è¿›ç¨‹ï¼ˆcmd.exeï¼‰ï¼Œä¹Ÿå…³é—­å®ƒä»¥å…³é—­ç»ˆç«¯çª—å£
            if parent_pid:
                try:
                    parent_proc = psutil.Process(parent_pid)
                    # æ£€æŸ¥çˆ¶è¿›ç¨‹æ˜¯å¦æ˜¯ cmd.exe
                    if 'cmd.exe' in parent_proc.name().lower():
                        parent_proc.terminate()
                        try:
                            parent_proc.wait(timeout=2)
                        except psutil.TimeoutExpired:
                            parent_proc.kill()
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass  # çˆ¶è¿›ç¨‹å¯èƒ½å·²ç»å…³é—­
            
            # é‡ç½®è¯¥è¿›ç¨‹è®°å½•
            self.processes[process_name] = None
            
            return {
                'success': True,
                'message': f'{process_name} stopped successfully',
                'process': process_name
            }
            
        except psutil.NoSuchProcess:
            # è¿›ç¨‹å·²ç»ä¸å­˜åœ¨
            self.processes[process_name] = None
            return {
                'success': True,
                'message': f'{process_name} was already stopped',
                'process': process_name
            }
        except Exception as e:
            return {
                'success': False,
                'message': f'Failed to stop {process_name}: {str(e)}',
                'error': 'ProcessStopFailed'
            }
    
    def get_process_status(self) -> dict:
        """è·å–æ‰€æœ‰è¿›ç¨‹çŠ¶æ€
        
        éå†æ‰€æœ‰è¿›ç¨‹è®°å½•ï¼Œä½¿ç”¨ _is_process_running æ£€æŸ¥æ¯ä¸ªè¿›ç¨‹çŠ¶æ€ï¼Œ
        è®¡ç®—è¿›ç¨‹è¿è¡Œæ—¶é—´ï¼ˆå¦‚æœå¯èƒ½ï¼‰ã€‚
        
        Returns:
            dict: æ‰€æœ‰è¿›ç¨‹çš„çŠ¶æ€ä¿¡æ¯ï¼ˆrunning/stopped, PID, uptimeï¼‰
        """
        status = {}
        
        for name in self.processes.keys():
            # ä½¿ç”¨ _is_process_running æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
            is_running = self._is_process_running(name)
            pid = self.processes.get(name)
            
            if is_running and pid:
                try:
                    proc = psutil.Process(pid)
                    # è®¡ç®—è¿›ç¨‹è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
                    create_time = proc.create_time()
                    uptime = int(time.time() - create_time)
                    
                    status[name] = {
                        'status': 'running',
                        'pid': pid,
                        'uptime': uptime
                    }
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    # è¿›ç¨‹ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®
                    status[name] = {
                        'status': 'stopped',
                        'pid': None,
                        'uptime': 0
                    }
            else:
                status[name] = {
                    'status': 'stopped',
                    'pid': None,
                    'uptime': 0
                }
        
        return status


# åˆ›å»ºå…¨å±€ ProcessManager å®ä¾‹
process_manager = ProcessManager()


@app.route('/api/databases', methods=['GET'])
def get_databases():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®åº“åˆ—è¡¨"""
    try:
        db_files = glob.glob(os.path.join(DATABASE_DIR, '*.db'))
        databases = [os.path.basename(f) for f in db_files]
        return jsonify({'databases': databases})
    except Exception as e:
        return jsonify({'error': str(e), 'databases': []}), 500

@app.route('/api/stats/<db_name>', methods=['GET'])
def get_stats(db_name):
    """è·å–æŒ‡å®šæ•°æ®åº“çš„ç»Ÿè®¡ä¿¡æ¯"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–æ´»è·ƒç”¨æˆ·æ•°
        cursor.execute("SELECT COUNT(DISTINCT user_id) FROM users")
        active_users = cursor.fetchone()[0] or 0
        
        # è·å–å‘å¸ƒå†…å®¹æ•°
        cursor.execute("SELECT COUNT(*) FROM posts")
        total_posts = cursor.fetchone()[0] or 0
        
        # è·å–ç”¨æˆ·è¯„è®ºæ•°
        cursor.execute("SELECT COUNT(*) FROM comments")
        total_comments = cursor.fetchone()[0] or 0
        
        # è·å–äº’åŠ¨ç‚¹èµæ•°ï¼ˆnum_likes + num_sharesï¼‰
        cursor.execute("""
            SELECT 
                COALESCE(SUM(num_likes), 0) + COALESCE(SUM(num_shares), 0) 
            FROM posts
        """)
        total_likes = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return jsonify({
            'activeUsers': active_users,
            'totalPosts': total_posts,
            'totalComments': total_comments,
            'totalLikes': int(total_likes)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({'status': 'ok'})

@app.route('/api/users/<db_name>', methods=['GET'])
def get_users(db_name):
    """è·å–ç”¨æˆ·åˆ—è¡¨"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT user_id, persona, creation_time, influence_score
            FROM users
            ORDER BY influence_score DESC
            LIMIT 100
        """)
        
        users = []
        for row in cursor.fetchall():
            users.append({
                'user_id': row[0],
                'persona': row[1],
                'creation_time': row[2],
                'influence_score': row[3]
            })
        
        conn.close()
        return jsonify({'users': users})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/user/<db_name>/<user_id>', methods=['GET'])
def get_user_detail(db_name, user_id):
    """è·å–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # åŸºæœ¬ä¿¡æ¯
        cursor.execute("""
            SELECT user_id, persona, background_labels, creation_time, 
                   follower_count, total_likes_received, total_shares_received,
                   total_comments_received, influence_score, is_influencer
            FROM users
            WHERE user_id = ?
        """, (user_id,))
        
        user_row = cursor.fetchone()
        if not user_row:
            conn.close()
            return jsonify({'error': 'User not found'}), 404
        
        # å‘å¸–æ•°
        cursor.execute("SELECT COUNT(*) FROM posts WHERE author_id = ?", (user_id,))
        post_count = cursor.fetchone()[0]
        
        # è¯„è®ºæ•°
        cursor.execute("SELECT COUNT(*) FROM comments WHERE author_id = ?", (user_id,))
        comment_count = cursor.fetchone()[0]
        
        # è·èµæ•°
        cursor.execute("""
            SELECT COALESCE(SUM(num_likes), 0) 
            FROM posts 
            WHERE author_id = ?
        """, (user_id,))
        likes_received = cursor.fetchone()[0]
        
        # å¹³å‡äº’åŠ¨ï¼ˆæ¯ç¯‡å¸–å­çš„å¹³å‡ç‚¹èµ+è¯„è®º+åˆ†äº«ï¼‰
        cursor.execute("""
            SELECT COALESCE(AVG(num_likes + num_comments + num_shares), 0)
            FROM posts
            WHERE author_id = ?
        """, (user_id,))
        avg_engagement = cursor.fetchone()[0]
        
        # å…³æ³¨åˆ—è¡¨
        cursor.execute("""
            SELECT followed_id, created_at
            FROM follows
            WHERE follower_id = ?
            ORDER BY created_at DESC
        """, (user_id,))
        following = [{'user_id': row[0], 'followed_at': row[1]} for row in cursor.fetchall()]
        
        # ç²‰ä¸åˆ—è¡¨
        cursor.execute("""
            SELECT follower_id, created_at
            FROM follows
            WHERE followed_id = ?
            ORDER BY created_at DESC
        """, (user_id,))
        followers = [{'user_id': row[0], 'followed_at': row[1]} for row in cursor.fetchall()]
        
        # è¯„è®ºå†å²
        cursor.execute("""
            SELECT comment_id, post_id, content, created_at, num_likes
            FROM comments
            WHERE author_id = ?
            ORDER BY created_at DESC
        """, (user_id,))
        comments = []
        for row in cursor.fetchall():
            comments.append({
                'comment_id': row[0],
                'post_id': row[1],
                'content': row[2],
                'created_at': row[3],
                'num_likes': row[4]
            })
        
        # å‘å¸ƒçš„å¸–å­
        cursor.execute("""
            SELECT post_id, content, created_at, num_likes, num_comments, num_shares
            FROM posts
            WHERE author_id = ?
            ORDER BY created_at DESC
        """, (user_id,))
        posts = []
        for row in cursor.fetchall():
            posts.append({
                'post_id': row[0],
                'content': row[1],
                'created_at': row[2],
                'num_likes': row[3],
                'num_comments': row[4],
                'num_shares': row[5]
            })
        
        conn.close()
        
        return jsonify({
            'basic_info': {
                'user_id': user_row[0],
                'persona': user_row[1],
                'background_labels': user_row[2],
                'creation_time': user_row[3],
                'influence_score': user_row[8],
                'is_influencer': bool(user_row[9])
            },
            'activity_stats': {
                'post_count': post_count,
                'comment_count': comment_count,
                'follower_count': user_row[4],
                'likes_received': int(likes_received),
                'avg_engagement': round(float(avg_engagement), 2)
            },
            'following': following,
            'followers': followers,
            'comments': comments,
            'posts': posts
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/posts/<db_name>', methods=['GET'])
def get_posts(db_name):
    """è·å–å¸–å­åˆ—è¡¨"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT post_id, author_id, content, created_at, 
                   num_likes, num_comments, num_shares,
                   (num_likes + num_comments + num_shares) as total_engagement
            FROM posts
            ORDER BY total_engagement DESC, created_at DESC
            LIMIT 100
        """)
        
        posts = []
        for row in cursor.fetchall():
            posts.append({
                'post_id': row[0],
                'author_id': row[1],
                'content': row[2],
                'created_at': row[3],
                'num_likes': row[4] or 0,
                'num_comments': row[5] or 0,
                'num_shares': row[6] or 0,
                'total_engagement': row[7] or 0
            })
        
        conn.close()
        return jsonify({'posts': posts})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/post/<db_name>/<post_id>', methods=['GET'])
def get_post_detail(db_name, post_id):
    """è·å–å¸–å­è¯¦ç»†ä¿¡æ¯"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # åŸºæœ¬ä¿¡æ¯
        cursor.execute("""
            SELECT post_id, author_id, content, created_at,
                   num_likes, num_comments, num_shares, news_type
            FROM posts
            WHERE post_id = ?
        """, (post_id,))
        
        post_row = cursor.fetchone()
        if not post_row:
            conn.close()
            return jsonify({'error': 'Post not found'}), 404
        
        # è·å–è¯„è®ºåˆ—è¡¨
        cursor.execute("""
            SELECT comment_id, author_id, content, created_at, num_likes
            FROM comments
            WHERE post_id = ?
            ORDER BY created_at DESC
        """, (post_id,))
        comments = []
        for row in cursor.fetchall():
            comments.append({
                'comment_id': row[0],
                'author_id': row[1],
                'content': row[2],
                'created_at': row[3],
                'num_likes': row[4]
            })
        
        # è·å–ç‚¹èµåˆ—è¡¨
        cursor.execute("""
            SELECT user_id, created_at
            FROM user_actions
            WHERE action_type IN ('like_post', 'like') AND target_id = ?
            ORDER BY created_at DESC
        """, (post_id,))
        likes = []
        for row in cursor.fetchall():
            likes.append({
                'user_id': row[0],
                'created_at': row[1]
            })
        
        # è·å–åˆ†äº«åˆ—è¡¨
        cursor.execute("""
            SELECT user_id, created_at
            FROM user_actions
            WHERE action_type = 'share_post' AND target_id = ?
            ORDER BY created_at DESC
        """, (post_id,))
        shares = []
        for row in cursor.fetchall():
            shares.append({
                'user_id': row[0],
                'created_at': row[1]
            })
        
        conn.close()
        
        return jsonify({
            'basic_info': {
                'post_id': post_row[0],
                'author_id': post_row[1],
                'content': post_row[2],
                'created_at': post_row[3],
                'topic': post_row[7] or 'General'
            },
            'engagement_stats': {
                'num_likes': post_row[4] or 0,
                'num_comments': post_row[5] or 0,
                'num_shares': post_row[6] or 0,
                'total_engagement': (post_row[4] or 0) + (post_row[5] or 0) + (post_row[6] or 0)
            },
            'comments': comments,
            'likes': likes,
            'shares': shares
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/services/status', methods=['GET'])
def get_services_status():
    """è·å–æ‰€æœ‰æœåŠ¡çš„çŠ¶æ€"""
    try:
        status = {}
        scripts = {
            'database': 'start_database_service.py',
            'platform': 'main.py',
            'balance': 'opinion_balance_launcher.py'
        }
        
        for service_name, script_name in scripts.items():
            # æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œè¯¥è„šæœ¬çš„Pythonè¿›ç¨‹
            is_running = False
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline')
                    if cmdline and any(script_name in str(cmd) for cmd in cmdline):
                        is_running = True
                        break
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            status[service_name] = 'running' if is_running else 'stopped'
        
        return jsonify({'services': status})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/services/cleanup', methods=['POST'])
def cleanup_services():
    """æ¸…ç†æ‰€æœ‰æœåŠ¡è¿›ç¨‹å’Œç«¯å£å ç”¨"""
    try:
        cleaned = []
        
        # æ¸…ç†æ‰€æœ‰æœåŠ¡è„šæœ¬çš„è¿›ç¨‹
        scripts = {
            'database': 'start_database_service.py',
            'platform': 'main.py',
            'balance': 'opinion_balance_launcher.py'
        }
        
        for service_name, script_name in scripts.items():
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline')
                    if cmdline and any(script_name in str(cmd) for cmd in cmdline):
                        parent = psutil.Process(proc.info['pid'])
                        for child in parent.children(recursive=True):
                            try:
                                child.kill()
                            except:
                                pass
                        parent.kill()
                        cleaned.append(f'{service_name} (PID: {proc.info["pid"]})')
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
        
        # æ¸…ç†ç«¯å£5000ï¼ˆæ•°æ®åº“æœåŠ¡ï¼‰
        import time
        time.sleep(0.5)
        for conn in psutil.net_connections():
            try:
                if conn.laddr.port == 5000 and conn.status == 'LISTEN':
                    proc = psutil.Process(conn.pid)
                    proc.kill()
                    cleaned.append(f'Port 5000 (PID: {conn.pid})')
            except:
                pass
        
        return jsonify({
            'message': 'Cleanup completed',
            'cleaned': cleaned
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/services/<service_name>/start', methods=['POST'])
def start_service(service_name):
    """å¯åŠ¨æœåŠ¡"""
    try:
        if service_name not in ['database', 'platform', 'balance']:
            return jsonify({'error': 'Invalid service name'}), 400
        
        # è·å–condaç¯å¢ƒåç§°ï¼ˆå¦‚æœæä¾›ï¼‰
        data = request.get_json() or {}
        conda_env = data.get('conda_env', '').strip()
        
        # æ ¹æ®æœåŠ¡åç§°å¯åŠ¨å¯¹åº”çš„è„šæœ¬
        scripts = {
            'database': 'src/start_database_service.py',
            'platform': 'src/main.py',
            'balance': 'src/opinion_balance_launcher.py'
        }
        
        script_path = scripts[service_name]
        if not os.path.exists(script_path):
            return jsonify({'error': f'Script not found: {script_path}'}), 404
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨è¿è¡Œ
        script_name = os.path.basename(script_path)
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = proc.info.get('cmdline')
                if cmdline and any(script_name in str(cmd) for cmd in cmdline):
                    return jsonify({'error': 'Service already running'}), 400
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        
        # å¦‚æœæ˜¯æ•°æ®åº“æœåŠ¡ï¼Œå…ˆæ¸…ç†ç«¯å£5000
        if service_name == 'database':
            import time
            # æ¸…ç†å¯èƒ½å ç”¨ç«¯å£5000çš„è¿›ç¨‹
            for conn in psutil.net_connections():
                try:
                    if conn.laddr.port == 5000 and conn.status == 'LISTEN':
                        proc = psutil.Process(conn.pid)
                        proc.kill()
                        time.sleep(0.5)  # ç­‰å¾…ç«¯å£é‡Šæ”¾
                except:
                    pass
        
        # å¯åŠ¨è¿›ç¨‹ - åœ¨æ–°çš„ç»ˆç«¯çª—å£ä¸­è¿è¡Œ
        if os.name == 'nt':  # Windows
            title = f"EvoCorps-{service_name}"
            
            if conda_env:
                # Windowsä¸Šï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶æ‰¹å¤„ç†æ–‡ä»¶æ¥æ‰§è¡Œå‘½ä»¤
                # è¿™æ ·å¯ä»¥ç¡®ä¿å‘½ä»¤æŒ‰é¡ºåºæ‰§è¡Œ
                import tempfile
                
                # åˆ›å»ºä¸´æ—¶æ‰¹å¤„ç†æ–‡ä»¶
                with tempfile.NamedTemporaryFile(mode='w', suffix='.bat', delete=False) as f:
                    batch_file = f.name
                    f.write('@echo off\n')
                    f.write(f'echo Activating conda environment: {conda_env}\n')
                    f.write(f'call conda activate {conda_env}\n')
                    f.write('if errorlevel 1 (\n')
                    f.write(f'    echo Failed to activate conda environment: {conda_env}\n')
                    f.write('    echo Please check if the environment exists: conda env list\n')
                    f.write('    pause\n')
                    f.write('    exit /b 1\n')
                    f.write(')\n')
                    f.write(f'echo Running: python {script_path}\n')
                    f.write(f'python {script_path}\n')
                    f.write('pause\n')
                
                # å¯åŠ¨æ–°ç»ˆç«¯è¿è¡Œæ‰¹å¤„ç†æ–‡ä»¶
                cmd = f'cmd /c start "{title}" cmd /k "{batch_file}"'
            else:
                # æ²¡æœ‰condaç¯å¢ƒï¼Œç›´æ¥è¿è¡Œ
                cmd = f'cmd /c start "{title}" cmd /k "python {script_path}"'
            
            subprocess.Popen(cmd, shell=True)
        else:  # Linux/Mac
            if conda_env:
                # Linux/Macä¸Šå…ˆæ¿€æ´»ç¯å¢ƒå†è¿è¡Œ
                cmd = f'bash -c "source $(conda info --base)/etc/profile.d/conda.sh && conda activate {conda_env} && python {script_path}"'
                subprocess.Popen(cmd, shell=True)
            else:
                subprocess.Popen(['python', script_path])
        
        return jsonify({'message': f'Service {service_name} started'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/services/<service_name>/stop', methods=['POST'])
def stop_service(service_name):
    """åœæ­¢æœåŠ¡"""
    try:
        if service_name not in ['database', 'platform', 'balance']:
            return jsonify({'error': 'Invalid service name'}), 400
        
        # æ ¹æ®è„šæœ¬åç§°æŸ¥æ‰¾å¹¶ç»ˆæ­¢è¿›ç¨‹
        scripts = {
            'database': 'start_database_service.py',
            'platform': 'main.py',
            'balance': 'opinion_balance_launcher.py'
        }
        
        script_name = scripts[service_name]
        killed_count = 0
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = proc.info.get('cmdline')
                if cmdline and any(script_name in str(cmd) for cmd in cmdline):
                    parent = psutil.Process(proc.info['pid'])
                    # ç»ˆæ­¢å­è¿›ç¨‹
                    for child in parent.children(recursive=True):
                        try:
                            child.kill()  # ä½¿ç”¨killè€Œä¸æ˜¯terminateï¼Œæ›´å¼ºåˆ¶
                        except:
                            pass
                    # ç»ˆæ­¢ä¸»è¿›ç¨‹
                    try:
                        parent.kill()  # ä½¿ç”¨killè€Œä¸æ˜¯terminate
                    except:
                        pass
                    killed_count += 1
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.TimeoutExpired):
                pass
        
        # å¦‚æœæ˜¯æ•°æ®åº“æœåŠ¡ï¼Œé¢å¤–æ£€æŸ¥å¹¶æ¸…ç†ç«¯å£5000ä¸Šçš„è¿›ç¨‹
        if service_name == 'database':
            import time
            time.sleep(1)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
            for conn in psutil.net_connections():
                if conn.laddr.port == 5000 and conn.status == 'LISTEN':
                    try:
                        proc = psutil.Process(conn.pid)
                        proc.kill()
                        killed_count += 1
                    except:
                        pass
        
        if killed_count == 0:
            return jsonify({'error': 'Service not running'}), 400
        
        return jsonify({'message': f'Service {service_name} stopped', 'killed_count': killed_count})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/experiments', methods=['GET'])
def get_experiments():
    """è·å–æ‰€æœ‰å·²ä¿å­˜çš„å®éªŒ"""
    try:
        experiments_dir = 'experiments'
        if not os.path.exists(experiments_dir):
            os.makedirs(experiments_dir)
            return jsonify({'experiments': []})
        
        experiments = []
        for exp_dir in os.listdir(experiments_dir):
            exp_path = os.path.join(experiments_dir, exp_dir)
            if os.path.isdir(exp_path):
                metadata_file = os.path.join(exp_path, 'metadata.json')
                if os.path.exists(metadata_file):
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        import json
                        metadata = json.load(f)
                        experiments.append(metadata)
        
        # æŒ‰æ—¶é—´æˆ³é™åºæ’åº
        experiments.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        return jsonify({'experiments': experiments})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/experiments/save', methods=['POST'])
def save_experiment():
    """ä¿å­˜å½“å‰å®éªŒ"""
    try:
        data = request.get_json()
        experiment_name = data.get('experiment_name', '')
        scenario_type = data.get('scenario_type', 'scenario_1')
        database_name = data.get('database_name', 'simulation.db')
        
        if not experiment_name:
            return jsonify({'error': 'Experiment name is required'}), 400
        
        # åˆ›å»ºå®éªŒç›®å½•
        import datetime
        import json
        import shutil
        
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        exp_id = f"experiment_{timestamp}"
        experiments_dir = 'experiments'
        exp_path = os.path.join(experiments_dir, exp_id)
        
        os.makedirs(exp_path, exist_ok=True)
        
        # ä¿å­˜æ•°æ®åº“å¿«ç…§
        db_source = os.path.join(DATABASE_DIR, database_name)
        if os.path.exists(db_source):
            db_dest = os.path.join(exp_path, 'database.db')
            shutil.copy2(db_source, db_dest)
            
            # åŒæ—¶å¤åˆ¶ WAL å’Œ SHM æ–‡ä»¶
            for suffix in ['-wal', '-shm']:
                aux_file = db_source + suffix
                if os.path.exists(aux_file):
                    shutil.copy2(aux_file, os.path.join(exp_path, f'database.db{suffix}'))
        else:
            return jsonify({'error': f'Database not found: {database_name}'}), 404
        
        # ä¿å­˜æƒ…ç»ªæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        emotion_dir = 'cognitive_memory'
        if os.path.exists(emotion_dir):
            emotion_dest = os.path.join(exp_path, 'cognitive_memory')
            os.makedirs(emotion_dest, exist_ok=True)
            for file in os.listdir(emotion_dir):
                if file.endswith('.json'):
                    shutil.copy2(os.path.join(emotion_dir, file), os.path.join(emotion_dest, file))
        
        # ä¿å­˜å…ƒä¿¡æ¯
        metadata = {
            'experiment_id': exp_id,
            'experiment_name': experiment_name,
            'scenario_type': scenario_type,
            'database_name': database_name,
            'timestamp': timestamp,
            'saved_at': datetime.datetime.now().isoformat(),
            'database_saved': os.path.exists(os.path.join(exp_path, 'database.db')),
            'emotion_data_saved': os.path.exists(os.path.join(exp_path, 'cognitive_memory'))
        }
        
        with open(os.path.join(exp_path, 'metadata.json'), 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'message': 'Experiment saved successfully',
            'experiment_id': exp_id,
            'metadata': metadata
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/experiments/<experiment_id>/load', methods=['POST'])
def load_experiment(experiment_id):
    """åŠ è½½å†å²å®éªŒ"""
    try:
        exp_path = os.path.join('experiments', experiment_id)
        
        if not os.path.exists(exp_path):
            return jsonify({'error': 'Experiment not found'}), 404
        
        # è¯»å–å…ƒä¿¡æ¯
        metadata_file = os.path.join(exp_path, 'metadata.json')
        if not os.path.exists(metadata_file):
            return jsonify({'error': 'Metadata not found'}), 404
        
        import json
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # æ¢å¤æ•°æ®åº“
        db_source = os.path.join(exp_path, 'database.db')
        if os.path.exists(db_source):
            import shutil
            # å¤‡ä»½å½“å‰æ•°æ®åº“
            current_db = os.path.join(DATABASE_DIR, 'simulation.db')
            if os.path.exists(current_db):
                backup_name = f"simulation_backup_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
                shutil.copy2(current_db, os.path.join(DATABASE_DIR, backup_name))
            
            # æ¢å¤å®éªŒæ•°æ®åº“
            shutil.copy2(db_source, current_db)
            
            # æ¢å¤ WAL å’Œ SHM æ–‡ä»¶
            for suffix in ['-wal', '-shm']:
                aux_file = db_source + suffix
                if os.path.exists(aux_file):
                    shutil.copy2(aux_file, current_db + suffix)
        
        # æ¢å¤æƒ…ç»ªæ•°æ®
        emotion_source = os.path.join(exp_path, 'cognitive_memory')
        if os.path.exists(emotion_source):
            import shutil
            emotion_dest = 'cognitive_memory'
            # å¤‡ä»½å½“å‰æƒ…ç»ªæ•°æ®
            if os.path.exists(emotion_dest):
                backup_name = f"cognitive_memory_backup_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
                shutil.copytree(emotion_dest, backup_name)
            
            # æ¸…ç©ºå¹¶æ¢å¤
            if os.path.exists(emotion_dest):
                shutil.rmtree(emotion_dest)
            shutil.copytree(emotion_source, emotion_dest)
        
        return jsonify({
            'message': 'Experiment loaded successfully',
            'metadata': metadata
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/experiments/<experiment_id>', methods=['DELETE'])
def delete_experiment(experiment_id):
    """åˆ é™¤å®éªŒ"""
    try:
        exp_path = os.path.join('experiments', experiment_id)
        
        if not os.path.exists(exp_path):
            return jsonify({'error': 'Experiment not found'}), 404
        
        import shutil
        shutil.rmtree(exp_path)
        
        return jsonify({'message': 'Experiment deleted successfully'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/visualization/<db_name>/emotion', methods=['GET'])
def get_emotion_data(db_name):
    """è·å–æƒ…ç»ªåˆ†ææ•°æ® - æ¯ä¸ªæ—¶é—´æ­¥çš„æƒ…ç»ªåº¦"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æƒ…ç»ªç›¸å…³çš„è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE '%emotion%'")
        emotion_tables = cursor.fetchall()
        
        # å¦‚æœæœ‰æƒ…ç»ªè¡¨ï¼Œä»ä¸­è·å–æ•°æ®
        if emotion_tables:
            # å‡è®¾æœ‰ä¸€ä¸ªemotion_trackingè¡¨
            cursor.execute("""
                SELECT timestep, AVG(emotion_score) as avg_emotion
                FROM emotion_tracking
                GROUP BY timestep
                ORDER BY timestep
            """)
            emotion_data = [{'timestep': row[0], 'emotion': round(row[1], 2)} for row in cursor.fetchall()]
        else:
            # å¦‚æœæ²¡æœ‰æƒ…ç»ªè¡¨ï¼Œä»ç”¨æˆ·è¡Œä¸ºæ¨æ–­æƒ…ç»ªï¼ˆåŸºäºäº’åŠ¨é¢‘ç‡ï¼‰
            cursor.execute("""
                SELECT 
                    CAST((julianday(created_at) - julianday((SELECT MIN(created_at) FROM posts))) AS INTEGER) as timestep,
                    COUNT(*) as activity_count
                FROM posts
                GROUP BY timestep
                ORDER BY timestep
                LIMIT 50
            """)
            rows = cursor.fetchall()
            
            # å°†æ´»åŠ¨æ•°é‡å½’ä¸€åŒ–ä¸ºæƒ…ç»ªåˆ†æ•°ï¼ˆ0-100ï¼‰
            if rows:
                max_activity = max(row[1] for row in rows)
                emotion_data = [
                    {
                        'timestep': row[0],
                        'emotion': round((row[1] / max_activity) * 100, 2) if max_activity > 0 else 50
                    }
                    for row in rows
                ]
            else:
                emotion_data = []
        
        conn.close()
        return jsonify({'emotion_data': emotion_data})
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/visualization/<db_name>/top-users', methods=['GET'])
def get_top_users(db_name):
    """è·å–Top10æ´»è·ƒç”¨æˆ·"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è®¡ç®—ç”¨æˆ·æ´»è·ƒåº¦ï¼ˆå‘å¸–æ•° + è¯„è®ºæ•° + è·èµæ•°ï¼‰
        cursor.execute("""
            SELECT 
                u.user_id,
                COALESCE(post_count, 0) as posts,
                COALESCE(comment_count, 0) as comments,
                COALESCE(u.total_likes_received, 0) as likes,
                (COALESCE(post_count, 0) + COALESCE(comment_count, 0) + COALESCE(u.total_likes_received, 0)) as total_activity
            FROM users u
            LEFT JOIN (
                SELECT author_id, COUNT(*) as post_count
                FROM posts
                GROUP BY author_id
            ) p ON u.user_id = p.author_id
            LEFT JOIN (
                SELECT author_id, COUNT(*) as comment_count
                FROM comments
                GROUP BY author_id
            ) c ON u.user_id = c.author_id
            ORDER BY total_activity DESC
            LIMIT 10
        """)
        
        top_users = []
        for row in cursor.fetchall():
            top_users.append({
                'user_id': row[0],
                'posts': row[1],
                'comments': row[2],
                'likes': row[3],
                'total_activity': row[4]
            })
        
        conn.close()
        return jsonify({'top_users': top_users})
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/visualization/<db_name>/network', methods=['GET'])
def get_network_data(db_name):
    """è·å–å…³ç³»ç½‘ç»œæ•°æ® - çŸ¥è¯†å›¾è°±æ ¼å¼ï¼ˆæ‰€æœ‰ç”¨æˆ·ã€å¸–å­ã€è¯„è®ºï¼‰"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        nodes = []
        edges = []
        
        # 1. è·å–æ‰€æœ‰ç”¨æˆ·èŠ‚ç‚¹
        cursor.execute("""
            SELECT 
                u.user_id,
                u.follower_count,
                u.influence_score,
                u.creation_time,
                u.persona,
                COALESCE(p.post_count, 0) as post_count,
                COALESCE(c.comment_count, 0) as comment_count
            FROM users u
            LEFT JOIN (
                SELECT author_id, COUNT(*) as post_count
                FROM posts
                GROUP BY author_id
            ) p ON u.user_id = p.author_id
            LEFT JOIN (
                SELECT author_id, COUNT(*) as comment_count
                FROM comments
                GROUP BY author_id
            ) c ON u.user_id = c.author_id
            ORDER BY u.influence_score DESC
        """)
        
        user_ids = set()
        for row in cursor.fetchall():
            user_id = row[0]
            user_ids.add(user_id)
            
            # è§£æpersonaè·å–è§’è‰²ä¿¡æ¯
            persona_str = row[4] or '{}'
            try:
                # å°è¯•JSONè§£æ
                persona = json.loads(persona_str) if isinstance(persona_str, str) else {}
            except:
                try:
                    # å¦‚æœJSONå¤±è´¥ï¼Œå°è¯•ast.literal_eval
                    import ast
                    persona = ast.literal_eval(persona_str) if isinstance(persona_str, str) else {}
                except:
                    persona = {}
            
            nodes.append({
                'id': user_id,
                'type': 'user',
                'name': user_id,
                'follower_count': row[1] or 0,
                'influence_score': row[2] or 0,
                'creation_time': row[3],
                'persona': persona,
                'post_count': row[5],
                'comment_count': row[6],
                'role': persona.get('personality_traits', {}).get('role', 'User') if isinstance(persona.get('personality_traits'), dict) else 'User'
            })
        
        # 2. è·å–æ‰€æœ‰å¸–å­
        cursor.execute("""
            SELECT 
                post_id,
                author_id,
                content,
                created_at,
                num_likes,
                num_comments,
                num_shares,
                news_type
            FROM posts
            ORDER BY (num_likes + num_comments + num_shares) DESC
        """)
        
        post_ids = set()
        for row in cursor.fetchall():
            post_id = row[0]
            author_id = row[1]
            post_ids.add(post_id)
            
            nodes.append({
                'id': post_id,
                'type': 'post',
                'name': post_id,
                'author_id': author_id,
                'content': row[2] or '',
                'created_at': row[3],
                'num_likes': row[4] or 0,
                'num_comments': row[5] or 0,
                'num_shares': row[6] or 0,
                'topic': row[7] or 'General'
            })
            
            # æ·»åŠ ç”¨æˆ·->å¸–å­çš„è¾¹ï¼ˆå‘å¸ƒå…³ç³»ï¼‰
            if author_id in user_ids:
                edges.append({
                    'source': author_id,
                    'target': post_id,
                    'type': 'published',
                    'label': 'å‘å¸ƒ'
                })
        
        # 3. è·å–æ‰€æœ‰è¯„è®º
        cursor.execute("""
            SELECT 
                comment_id,
                post_id,
                author_id,
                content,
                created_at,
                num_likes
            FROM comments
            ORDER BY num_likes DESC
        """)
        
        for row in cursor.fetchall():
            comment_id = row[0]
            post_id = row[1]
            author_id = row[2]
            
            nodes.append({
                'id': comment_id,
                'type': 'comment',
                'name': comment_id,
                'post_id': post_id,
                'author_id': author_id,
                'content': row[3] or '',
                'created_at': row[4],
                'num_likes': row[5] or 0
            })
            
            # æ·»åŠ ç”¨æˆ·->è¯„è®ºçš„è¾¹
            if author_id in user_ids:
                edges.append({
                    'source': author_id,
                    'target': comment_id,
                    'type': 'commented',
                    'label': 'è¯„è®º'
                })
            
            # æ·»åŠ è¯„è®º->å¸–å­çš„è¾¹
            if post_id in post_ids:
                edges.append({
                    'source': comment_id,
                    'target': post_id,
                    'type': 'comment_on',
                    'label': 'è¯„è®ºäº'
                })
        
        # 4. è·å–æ‰€æœ‰å…³æ³¨å…³ç³»
        cursor.execute("""
            SELECT follower_id, followed_id
            FROM follows
        """)
        
        for row in cursor.fetchall():
            if row[0] in user_ids and row[1] in user_ids:
                edges.append({
                    'source': row[0],
                    'target': row[1],
                    'type': 'follows',
                    'label': 'å…³æ³¨'
                })
        
        # 5. è·å–æ‰€æœ‰ç‚¹èµå…³ç³»ï¼ˆç”¨æˆ·ç‚¹èµå¸–å­ï¼‰
        cursor.execute("""
            SELECT user_id, target_id
            FROM user_actions
            WHERE action_type IN ('like_post', 'like')
        """)
        
        for row in cursor.fetchall():
            if row[0] in user_ids and row[1] in post_ids:
                edges.append({
                    'source': row[0],
                    'target': row[1],
                    'type': 'liked',
                    'label': 'ç‚¹èµ'
                })
        
        # 6. è·å–æ‰€æœ‰åˆ†äº«å…³ç³»ï¼ˆç”¨æˆ·åˆ†äº«å¸–å­ï¼‰
        cursor.execute("""
            SELECT user_id, target_id
            FROM user_actions
            WHERE action_type = 'share_post'
        """)
        
        for row in cursor.fetchall():
            if row[0] in user_ids and row[1] in post_ids:
                edges.append({
                    'source': row[0],
                    'target': row[1],
                    'type': 'shared',
                    'label': 'åˆ†äº«'
                })
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        cursor.execute("SELECT COUNT(DISTINCT user_id) FROM users")
        total_users = cursor.fetchone()[0] or 0
        
        cursor.execute("SELECT COUNT(*) FROM posts")
        total_posts = cursor.fetchone()[0] or 0
        
        cursor.execute("SELECT COUNT(*) FROM comments")
        total_comments = cursor.fetchone()[0] or 0
        
        cursor.execute("SELECT COUNT(*) FROM follows")
        total_follows = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return jsonify({
            'nodes': nodes,
            'edges': edges,
            'stats': {
                'total_users': total_users,
                'total_posts': total_posts,
                'total_comments': total_comments,
                'total_follows': total_follows,
                'displayed_nodes': len(nodes),
                'displayed_edges': len(edges)
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/visualization/<db_name>/opinion-balance', methods=['GET'])
def get_opinion_balance_data(db_name):
    """è·å–èˆ†è®ºå¹³è¡¡æ•°æ®"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰èˆ†è®ºå¹³è¡¡ç›¸å…³çš„è¡¨
        cursor.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='table' AND (name LIKE '%opinion%' OR name LIKE '%intervention%')
        """)
        opinion_tables = [row[0] for row in cursor.fetchall()]
        
        result = {
            'has_data': len(opinion_tables) > 0,
            'tables': opinion_tables,
            'monitoring_stats': {},
            'intervention_stats': {},
            'timeline': []
        }
        
        if 'opinion_monitoring' in opinion_tables:
            # ç›‘æ§ç»Ÿè®¡
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_monitored,
                    SUM(CASE WHEN requires_intervention = 1 THEN 1 ELSE 0 END) as intervention_needed
                FROM opinion_monitoring
            """)
            row = cursor.fetchone()
            result['monitoring_stats'] = {
                'total_monitored': row[0] or 0,
                'intervention_needed': row[1] or 0,
                'intervention_rate': round((row[1] or 0) / max(row[0] or 1, 1) * 100, 1)
            }
        
        if 'opinion_interventions' in opinion_tables:
            # å¹²é¢„ç»Ÿè®¡
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_interventions,
                    AVG(effectiveness_score) as avg_effectiveness
                FROM opinion_interventions
            """)
            row = cursor.fetchone()
            result['intervention_stats'] = {
                'total_interventions': row[0] or 0,
                'avg_effectiveness': round(row[1] or 0, 2)
            }
            
            # æ—¶é—´çº¿æ•°æ®
            cursor.execute("""
                SELECT 
                    DATE(created_at) as date,
                    COUNT(*) as intervention_count
                FROM opinion_interventions
                GROUP BY date
                ORDER BY date
                LIMIT 30
            """)
            result['timeline'] = [
                {'date': row[0], 'interventions': row[1]}
                for row in cursor.fetchall()
            ]
        
        conn.close()
        return jsonify(result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/experiment', methods=['GET'])
def get_experiment_config():
    """è·å–å®éªŒé…ç½®"""
    try:
        config_path = 'configs/experiment_config.json'
        if not os.path.exists(config_path):
            return jsonify({'error': 'Config file not found'}), 404
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify(config)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/config/experiment', methods=['POST'])
def save_experiment_config():
    """ä¿å­˜å®éªŒé…ç½® - åªä¿®æ”¹æ•°å€¼ï¼Œå®Œå…¨ä¿æŒåŸæ ¼å¼"""
    try:
        config_path = 'configs/experiment_config.json'
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # è¯»å–åŸæ–‡ä»¶å†…å®¹ï¼ˆæ–‡æœ¬å½¢å¼ï¼‰
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è¯»å–åŸé…ç½®ï¼ˆJSONå½¢å¼ï¼‰
        original_config = json.loads(content)
        
        # åªæ›¿æ¢ä¿®æ”¹çš„å­—æ®µå€¼ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç¡®æ›¿æ¢
        import re
        
        # å¤„ç† num_users
        if 'num_users' in data and data['num_users'] != original_config.get('num_users'):
            pattern = r'("num_users":\s*)(\d+)'
            content = re.sub(pattern, r'\g<1>' + str(data['num_users']), content)
        
        # å¤„ç† num_time_steps
        if 'num_time_steps' in data and data['num_time_steps'] != original_config.get('num_time_steps'):
            pattern = r'("num_time_steps":\s*)(\d+)'
            content = re.sub(pattern, r'\g<1>' + str(data['num_time_steps']), content)
        
        # å¤„ç† engine
        if 'engine' in data and data['engine'] != original_config.get('engine'):
            pattern = r'("engine":\s*)"([^"]*)"'
            content = re.sub(pattern, r'\g<1>"' + data['engine'] + '"', content)
        
        # å¤„ç† temperature
        if 'temperature' in data and data['temperature'] != original_config.get('temperature'):
            pattern = r'("temperature":\s*)(\d+\.?\d*)'
            content = re.sub(pattern, r'\g<1>' + str(data['temperature']), content)
        
        # å¤„ç† reset_db
        if 'reset_db' in data and data['reset_db'] != original_config.get('reset_db'):
            pattern = r'("reset_db":\s*)(true|false)'
            content = re.sub(pattern, r'\g<1>' + ('true' if data['reset_db'] else 'false'), content)
        
        # ä¿å­˜ä¿®æ”¹åçš„å†…å®¹
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return jsonify({'message': 'Config saved successfully'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/interview/send', methods=['POST'])
def send_interview():
    """å‘é€‰ä¸­çš„ç”¨æˆ·å‘é€é‡‡è®¿é—®é¢˜å¹¶è·å–å›ç­”"""
    try:
        data = request.get_json()
        database = data.get('database')
        user_ids = data.get('user_ids', [])
        question = data.get('question', '')
        
        if not database or not user_ids or not question:
            return jsonify({'error': 'Missing required parameters'}), 400
        
        db_path = os.path.join(DATABASE_DIR, database)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        responses = []
        
        for user_id in user_ids:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            cursor.execute("""
                SELECT user_id, persona, background_labels
                FROM users
                WHERE user_id = ?
            """, (user_id,))
            
            user_row = cursor.fetchone()
            if not user_row:
                continue
            
            user_persona = user_row[1]
            background = user_row[2] if user_row[2] else ''
            
            # æ ¹æ®ç”¨æˆ·çš„personaå’Œå®é™…è¡Œä¸ºç”Ÿæˆå›ç­”
            answer = generate_interview_answer(user_persona, background, question, user_id, db_path)
            
            responses.append({
                'user_id': user_id,
                'question': question,
                'answer': answer,
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        conn.close()
        
        return jsonify({
            'message': 'Interview sent successfully',
            'responses': responses
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/interview/send-stream', methods=['POST'])
def send_interview_stream():
    """æµå¼å‘é€é‡‡è®¿é—®é¢˜å¹¶è·å–å›ç­”"""
    from flask import Response, stream_with_context
    
    data = request.get_json()
    database = data.get('database')
    user_ids = data.get('user_ids', [])
    question = data.get('question', '')
    
    if not database or not user_ids or not question:
        return jsonify({'error': 'Missing required parameters'}), 400
    
    db_path = os.path.join(DATABASE_DIR, database)
    if not os.path.exists(db_path):
        return jsonify({'error': 'Database not found'}), 404
    
    def generate():
        """ç”Ÿæˆå™¨å‡½æ•°ï¼Œé€ä¸ªç”¨æˆ·æµå¼è¿”å›å›ç­”"""
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        try:
            for user_id in user_ids:
                # è·å–ç”¨æˆ·ä¿¡æ¯
                cursor.execute("""
                    SELECT user_id, persona, background_labels
                    FROM users
                    WHERE user_id = ?
                """, (user_id,))
                
                user_row = cursor.fetchone()
                if not user_row:
                    continue
                
                user_persona = user_row[1]
                background = user_row[2] if user_row[2] else ''
                
                # å‘é€å¼€å§‹æ ‡è®°
                yield f"data: {json.dumps({'type': 'start', 'user_id': user_id}, ensure_ascii=False)}\n\n"
                
                # æµå¼ç”Ÿæˆå›ç­”
                for chunk in generate_interview_answer_stream(user_persona, background, question, user_id, db_path):
                    yield f"data: {json.dumps({'type': 'chunk', 'user_id': user_id, 'content': chunk}, ensure_ascii=False)}\n\n"
                
                # å‘é€å®Œæˆæ ‡è®°
                yield f"data: {json.dumps({'type': 'done', 'user_id': user_id, 'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}, ensure_ascii=False)}\n\n"
            
            # æ‰€æœ‰ç”¨æˆ·å®Œæˆ
            yield f"data: {json.dumps({'type': 'complete'}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
        finally:
            conn.close()
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


def generate_interview_answer_stream(persona, background, question, user_id, db_path):
    """æµå¼ç”Ÿæˆé‡‡è®¿å›ç­”"""
    import json
    
    # å¦‚æœAIä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ¿å›ç­”
    if not AI_AVAILABLE:
        # è·å–ç”¨æˆ·æ•°æ®
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT content, num_likes, num_comments FROM posts WHERE author_id = ? LIMIT 5", (user_id,))
        user_posts = cursor.fetchall()
        cursor.execute("SELECT content FROM comments WHERE author_id = ? LIMIT 5", (user_id,))
        user_comments = cursor.fetchall()
        cursor.execute("SELECT COUNT(*) FROM user_actions WHERE user_id = ? AND action_type IN ('like_post', 'like')", (user_id,))
        like_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM follows WHERE follower_id = ?", (user_id,))
        following_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM follows WHERE followed_id = ?", (user_id,))
        follower_count = cursor.fetchone()[0]
        conn.close()
        
        # è§£æpersona
        persona_info = {}
        try:
            if isinstance(persona, str):
                try:
                    persona_info = json.loads(persona)
                except:
                    fixed_str = persona.replace("'", '"').replace('None', 'null').replace('True', 'true').replace('False', 'false')
                    persona_info = json.loads(fixed_str)
            else:
                persona_info = persona
        except:
            persona_info = {'description': str(persona)}
        
        # ç”Ÿæˆæ¨¡æ¿å›ç­”å¹¶é€å­—è¿”å›
        answer = generate_template_answer(persona_info, user_posts, user_comments, like_count, following_count, follower_count, question)
        
        # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼Œæ¯æ¬¡è¿”å›å‡ ä¸ªå­—
        import time
        for i in range(0, len(answer), 3):
            chunk = answer[i:i+3]
            yield chunk
            time.sleep(0.05)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
        return
    
    # ä½¿ç”¨AIæµå¼ç”Ÿæˆ
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # è·å–ç”¨æˆ·è¡Œä¸ºæ•°æ®
    cursor.execute("SELECT content, num_likes, num_comments FROM posts WHERE author_id = ? ORDER BY created_at DESC LIMIT 5", (user_id,))
    user_posts = cursor.fetchall()
    cursor.execute("SELECT content FROM comments WHERE author_id = ? ORDER BY created_at DESC LIMIT 5", (user_id,))
    user_comments = cursor.fetchall()
    cursor.execute("SELECT COUNT(*) FROM user_actions WHERE user_id = ? AND action_type IN ('like_post', 'like')", (user_id,))
    like_count = cursor.fetchone()[0]
    cursor.execute("SELECT COUNT(*) FROM follows WHERE follower_id = ?", (user_id,))
    following_count = cursor.fetchone()[0]
    cursor.execute("SELECT COUNT(*) FROM follows WHERE followed_id = ?", (user_id,))
    follower_count = cursor.fetchone()[0]
    conn.close()
    
    # è§£æpersona
    persona_info = {}
    try:
        if isinstance(persona, str):
            try:
                persona_info = json.loads(persona)
            except:
                fixed_str = persona.replace("'", '"').replace('None', 'null').replace('True', 'true').replace('False', 'false')
                persona_info = json.loads(fixed_str)
        else:
            persona_info = persona
    except:
        persona_info = {'description': str(persona)}
    
    # æ„å»ºç”¨æˆ·è¡Œä¸ºæ‘˜è¦
    behavior_summary = f"""
ç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ï¼š
- å‘å¸–æ•°ï¼š{len(user_posts)}ç¯‡
- è¯„è®ºæ•°ï¼š{len(user_comments)}æ¡
- ç‚¹èµæ•°ï¼š{like_count}æ¬¡
- å…³æ³¨æ•°ï¼š{following_count}äºº
- ç²‰ä¸æ•°ï¼š{follower_count}äºº
"""
    
    if user_posts:
        behavior_summary += "\næœ€è¿‘å‘å¸ƒçš„å¸–å­ï¼š\n"
        for i, post in enumerate(user_posts[:3], 1):
            content = post[0][:100] + "..." if len(post[0]) > 100 else post[0]
            behavior_summary += f"{i}. {content} (è·å¾—{post[1]}ä¸ªèµï¼Œ{post[2]}æ¡è¯„è®º)\n"
    
    if user_comments:
        behavior_summary += "\næœ€è¿‘çš„è¯„è®ºï¼š\n"
        for i, comment in enumerate(user_comments[:3], 1):
            content = comment[0][:100] + "..." if len(comment[0]) > 100 else comment[0]
            behavior_summary += f"{i}. {content}\n"
    
    # æ„å»ºæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªç¤¾äº¤åª’ä½“å¹³å°çš„ç”¨æˆ·ï¼Œæ­£åœ¨æ¥å—é‡‡è®¿ã€‚è¯·æ ¹æ®ä½ çš„ä¸ªäººèƒŒæ™¯ã€æ€§æ ¼ç‰¹å¾å’Œåœ¨å¹³å°ä¸Šçš„å®é™…è¡Œä¸ºæ¥å›ç­”é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. å›ç­”è¦è‡ªç„¶ã€çœŸå®ï¼Œç¬¦åˆä½ çš„äººè®¾å’Œè¡Œä¸ºæ¨¡å¼
2. ç»“åˆä½ åœ¨å¹³å°ä¸Šçš„å®é™…æ´»åŠ¨ï¼ˆå‘å¸–ã€è¯„è®ºã€ç‚¹èµç­‰ï¼‰æ¥å›ç­”
3. å›ç­”é•¿åº¦æ§åˆ¶åœ¨100-200å­—ä¹‹é—´
4. ç”¨ç¬¬ä¸€äººç§°å›ç­”ï¼Œå±•ç°ä¸ªæ€§åŒ–çš„è¯­è¨€é£æ ¼
5. å¦‚æœé—®é¢˜ä¸ä½ çš„è¡Œä¸ºç›¸å…³ï¼Œè¦å¼•ç”¨å…·ä½“çš„æ•°æ®æˆ–ä¾‹å­
6. ä¿æŒå›ç­”çš„å¤šæ ·æ€§ï¼Œé¿å…åƒç¯‡ä¸€å¾‹"""
    
    user_prompt = f"""æˆ‘çš„ä¸ªäººä¿¡æ¯ï¼š
{json.dumps(persona_info, ensure_ascii=False, indent=2)}

{behavior_summary}

ç°åœ¨è¯·å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{question}

è¯·ä»¥ç¬¬ä¸€äººç§°å›ç­”ï¼Œç»“åˆæˆ‘çš„èƒŒæ™¯å’Œåœ¨å¹³å°ä¸Šçš„å®é™…è¡Œä¸ºã€‚"""
    
    try:
        # ä½¿ç”¨æµå¼API
        openai_client, selected_model = multi_model_selector.create_openai_client(role="interview")
        
        stream = openai_client.chat.completions.create(
            model=selected_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.8,
            max_tokens=300,
            stream=True
        )
        
        for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
                
    except Exception as e:
        print(f"âš ï¸ AIæµå¼ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # å›é€€åˆ°æ¨¡æ¿å›ç­”
        answer = generate_template_answer(persona_info, user_posts, user_comments, like_count, following_count, follower_count, question)
        import time
        for i in range(0, len(answer), 3):
            chunk = answer[i:i+3]
            yield chunk
            time.sleep(0.05)

def generate_interview_answer(persona, background, question, user_id, db_path):
    """ä½¿ç”¨AIæ¨¡å‹æ ¹æ®ç”¨æˆ·personaå’Œå®é™…è¡Œä¸ºç”Ÿæˆé‡‡è®¿å›ç­”"""
    import json
    
    # è¿æ¥æ•°æ®åº“è·å–ç”¨æˆ·è¡Œä¸ºæ•°æ®
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # è·å–ç”¨æˆ·çš„å‘å¸–æ•°æ®
    cursor.execute("""
        SELECT content, num_likes, num_comments, created_at
        FROM posts
        WHERE author_id = ?
        ORDER BY created_at DESC
        LIMIT 5
    """, (user_id,))
    user_posts = cursor.fetchall()
    
    # è·å–ç”¨æˆ·çš„è¯„è®ºæ•°æ®
    cursor.execute("""
        SELECT content, created_at
        FROM comments
        WHERE author_id = ?
        ORDER BY created_at DESC
        LIMIT 5
    """, (user_id,))
    user_comments = cursor.fetchall()
    
    # è·å–ç”¨æˆ·ç‚¹èµçš„å¸–å­
    cursor.execute("""
        SELECT COUNT(*) FROM user_actions
        WHERE user_id = ? AND action_type IN ('like_post', 'like')
    """, (user_id,))
    like_count = cursor.fetchone()[0]
    
    # è·å–ç”¨æˆ·å…³æ³¨çš„äººæ•°
    cursor.execute("""
        SELECT COUNT(*) FROM follows
        WHERE follower_id = ?
    """, (user_id,))
    following_count = cursor.fetchone()[0]
    
    # è·å–ç”¨æˆ·è¢«å…³æ³¨çš„äººæ•°
    cursor.execute("""
        SELECT COUNT(*) FROM follows
        WHERE followed_id = ?
    """, (user_id,))
    follower_count = cursor.fetchone()[0]
    
    conn.close()
    
    # è§£æpersonaï¼ˆå¦‚æœæ˜¯JSONæ ¼å¼ï¼‰
    persona_info = {}
    try:
        if isinstance(persona, str):
            try:
                persona_info = json.loads(persona)
            except:
                fixed_str = persona.replace("'", '"').replace('None', 'null').replace('True', 'true').replace('False', 'false')
                persona_info = json.loads(fixed_str)
        else:
            persona_info = persona
    except:
        persona_info = {'description': str(persona)}
    
    # å¦‚æœAIæ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨æ”¹è¿›çš„æ¨¡æ¿å›ç­”
    if not AI_AVAILABLE:
        return generate_template_answer(persona_info, user_posts, user_comments, like_count, following_count, follower_count, question)
    
    # æ„å»ºç”¨æˆ·è¡Œä¸ºæ‘˜è¦
    behavior_summary = f"""
ç”¨æˆ·è¡Œä¸ºç»Ÿè®¡ï¼š
- å‘å¸–æ•°ï¼š{len(user_posts)}ç¯‡
- è¯„è®ºæ•°ï¼š{len(user_comments)}æ¡
- ç‚¹èµæ•°ï¼š{like_count}æ¬¡
- å…³æ³¨æ•°ï¼š{following_count}äºº
- ç²‰ä¸æ•°ï¼š{follower_count}äºº
"""
    
    # æ·»åŠ æœ€è¿‘çš„å¸–å­å†…å®¹
    if user_posts:
        behavior_summary += "\næœ€è¿‘å‘å¸ƒçš„å¸–å­ï¼š\n"
        for i, post in enumerate(user_posts[:3], 1):
            content = post[0][:100] + "..." if len(post[0]) > 100 else post[0]
            behavior_summary += f"{i}. {content} (è·å¾—{post[1]}ä¸ªèµï¼Œ{post[2]}æ¡è¯„è®º)\n"
    
    # æ·»åŠ æœ€è¿‘çš„è¯„è®ºå†…å®¹
    if user_comments:
        behavior_summary += "\næœ€è¿‘çš„è¯„è®ºï¼š\n"
        for i, comment in enumerate(user_comments[:3], 1):
            content = comment[0][:100] + "..." if len(comment[0]) > 100 else comment[0]
            behavior_summary += f"{i}. {content}\n"
    
    # æ„å»ºAIæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªç¤¾äº¤åª’ä½“å¹³å°çš„ç”¨æˆ·ï¼Œæ­£åœ¨æ¥å—é‡‡è®¿ã€‚è¯·æ ¹æ®ä½ çš„ä¸ªäººèƒŒæ™¯ã€æ€§æ ¼ç‰¹å¾å’Œåœ¨å¹³å°ä¸Šçš„å®é™…è¡Œä¸ºæ¥å›ç­”é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. å›ç­”è¦è‡ªç„¶ã€çœŸå®ï¼Œç¬¦åˆä½ çš„äººè®¾å’Œè¡Œä¸ºæ¨¡å¼
2. ç»“åˆä½ åœ¨å¹³å°ä¸Šçš„å®é™…æ´»åŠ¨ï¼ˆå‘å¸–ã€è¯„è®ºã€ç‚¹èµç­‰ï¼‰æ¥å›ç­”
3. å›ç­”é•¿åº¦æ§åˆ¶åœ¨100-200å­—ä¹‹é—´
4. ç”¨ç¬¬ä¸€äººç§°å›ç­”ï¼Œå±•ç°ä¸ªæ€§åŒ–çš„è¯­è¨€é£æ ¼
5. å¦‚æœé—®é¢˜ä¸ä½ çš„è¡Œä¸ºç›¸å…³ï¼Œè¦å¼•ç”¨å…·ä½“çš„æ•°æ®æˆ–ä¾‹å­
6. ä¿æŒå›ç­”çš„å¤šæ ·æ€§ï¼Œé¿å…åƒç¯‡ä¸€å¾‹"""
    
    user_prompt = f"""æˆ‘çš„ä¸ªäººä¿¡æ¯ï¼š
{json.dumps(persona_info, ensure_ascii=False, indent=2)}

{behavior_summary}

ç°åœ¨è¯·å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{question}

è¯·ä»¥ç¬¬ä¸€äººç§°å›ç­”ï¼Œç»“åˆæˆ‘çš„èƒŒæ™¯å’Œåœ¨å¹³å°ä¸Šçš„å®é™…è¡Œä¸ºã€‚"""
    
    try:
        # ä½¿ç”¨é¡¹ç›®çš„å¤šæ¨¡å‹é€‰æ‹©å™¨åˆ›å»ºå®¢æˆ·ç«¯
        openai_client, selected_model = multi_model_selector.create_openai_client(role="interview")
        
        # è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå›ç­”
        answer = Utils.generate_llm_response(
            openai_client=openai_client,
            engine=selected_model,
            prompt=user_prompt,
            system_message=system_prompt,
            temperature=0.8,  # è¾ƒé«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´å¤šæ ·åŒ–çš„å›ç­”
            max_tokens=300
        )
        
        return answer
        
    except Exception as e:
        # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›æ¨¡æ¿å›ç­”
        print(f"âš ï¸ AIç”Ÿæˆå›ç­”å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        return generate_template_answer(persona_info, user_posts, user_comments, like_count, following_count, follower_count, question)


def generate_template_answer(persona_info, user_posts, user_comments, like_count, following_count, follower_count, question):
    """ç”ŸæˆåŸºäºæ¨¡æ¿çš„å›ç­”ï¼ˆå½“AIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
    question_lower = question.lower()
    
    # è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
    name = persona_info.get('name', 'ç”¨æˆ·')
    profession = persona_info.get('profession', 'æ™®é€šç”¨æˆ·')
    background = persona_info.get('background', 'å„ç§è¯é¢˜')
    
    # è®¡ç®—æ´»è·ƒåº¦
    total_activity = len(user_posts) + len(user_comments)
    activity_level = "éå¸¸æ´»è·ƒ" if total_activity > 10 else "æ´»è·ƒ" if total_activity > 5 else "æ–°æ‰‹"
    
    # æ ¹æ®é—®é¢˜ç±»å‹ç”Ÿæˆå›ç­”
    if any(keyword in question_lower for keyword in ['å‘å¸–', 'å‘å¸ƒ', 'å†…å®¹', 'åˆ†äº«', 'å¸–å­', 'å‘è¡¨']):
        if user_posts:
            avg_likes = sum(p[1] or 0 for p in user_posts) / len(user_posts)
            return f"æˆ‘åœ¨å¹³å°ä¸Šå‘å¸ƒäº†{len(user_posts)}ç¯‡å†…å®¹ï¼Œå¹³å‡æ¯ç¯‡è·å¾—{avg_likes:.1f}ä¸ªç‚¹èµã€‚ä½œä¸º{profession}ï¼Œæˆ‘ä¸»è¦åˆ†äº«å…³äº{background}çš„å†…å®¹ã€‚æˆ‘è§‰å¾—é€šè¿‡å‘å¸–å¯ä»¥å’Œå¤§å®¶äº¤æµæƒ³æ³•ï¼Œä¹Ÿèƒ½è·å¾—ä¸åŒçš„è§‚ç‚¹ã€‚"
        else:
            return f"æˆ‘ç›®å‰è¿˜æ²¡æœ‰å‘å¸ƒè¿‡å†…å®¹ï¼Œä¸»è¦æ˜¯åœ¨è§‚å¯Ÿå’Œå­¦ä¹ ã€‚ä½œä¸º{name}ï¼Œæˆ‘æ›´å€¾å‘äºå…ˆäº†è§£å¹³å°æ°›å›´å†å‚ä¸ã€‚ä¸è¿‡æˆ‘å¯¹{background}ç›¸å…³çš„è¯é¢˜å¾ˆæ„Ÿå…´è¶£ã€‚"
    
    elif any(keyword in question_lower for keyword in ['äº’åŠ¨', 'è¯„è®º', 'äº¤æµ', 'è®¨è®º', 'å‚ä¸']):
        if user_comments:
            return f"æˆ‘æ¯”è¾ƒ{activity_level}ï¼Œå‘è¡¨è¿‡{len(user_comments)}æ¡è¯„è®ºã€‚æˆ‘å–œæ¬¢ä¸ä»–äººçœŸè¯šåœ°äº¤æµæƒ³æ³•ã€‚ä½œä¸º{profession}ï¼Œæˆ‘è®¤ä¸ºè‰¯å¥½çš„äº’åŠ¨èƒ½ä¿ƒè¿›ç›¸äº’ç†è§£ï¼Œä¹Ÿèƒ½è®©æˆ‘å­¦åˆ°æ–°ä¸œè¥¿ã€‚"
        else:
            return f"æˆ‘ç›®å‰ä¸»è¦æ˜¯æµè§ˆå†…å®¹ï¼Œè¿˜æ²¡æœ‰å¤ªå¤šè¯„è®ºã€‚ä¸è¿‡æˆ‘ä¼šåœ¨åˆé€‚çš„æ—¶å€™å‚ä¸è®¨è®ºï¼Œç‰¹åˆ«æ˜¯å…³äº{background}çš„è¯é¢˜ã€‚"
    
    elif any(keyword in question_lower for keyword in ['å–œæ¬¢', 'åå¥½', 'ç‚¹èµ', 'å…³æ³¨', 'å…´è¶£']):
        if like_count > 0:
            return f"æˆ‘ç‚¹èµäº†{like_count}ä¸ªå†…å®¹ï¼Œå…³æ³¨äº†{following_count}ä¸ªç”¨æˆ·ï¼Œæœ‰{follower_count}ä¸ªç²‰ä¸ã€‚æˆ‘æ¯”è¾ƒå…³æ³¨{background}ç›¸å…³çš„è¯é¢˜ã€‚æˆ‘çš„å…´è¶£æ¯”è¾ƒå¹¿æ³›ï¼Œå–œæ¬¢ä»ä¸åŒè§’åº¦çœ‹é—®é¢˜ã€‚"
        else:
            return f"æˆ‘è¿˜åœ¨æ¢ç´¢å¹³å°ï¼Œå¯»æ‰¾æ„Ÿå…´è¶£çš„å†…å®¹ã€‚ä½œä¸º{profession}ï¼Œæˆ‘å¯¹{background}ç‰¹åˆ«æ„Ÿå…´è¶£ï¼Œå¸Œæœ›èƒ½æ‰¾åˆ°æ›´å¤šå¿—åŒé“åˆçš„äººã€‚"
    
    elif any(keyword in question_lower for keyword in ['çœ‹æ³•', 'è§‚ç‚¹', 'è®¤ä¸º', 'æƒ³æ³•', 'æ€åº¦', 'å¦‚ä½•çœ‹å¾…']):
        behavior_desc = f"å‘å¸ƒäº†{len(user_posts)}ç¯‡å†…å®¹" if user_posts else f"å‘è¡¨äº†{len(user_comments)}æ¡è¯„è®º" if user_comments else "è¿˜åœ¨è§‚å¯Ÿ"
        return f"ä»æˆ‘åœ¨å¹³å°ä¸Šçš„è¡¨ç°æ¥çœ‹ï¼ˆ{behavior_desc}ï¼‰ï¼Œæˆ‘å€¾å‘äºç†æ€§åœ°çœ‹å¾…é—®é¢˜ã€‚æˆ‘è®¤ä¸ºéœ€è¦å¤šè§’åº¦æ€è€ƒã€‚ä½œä¸º{profession}ï¼Œæˆ‘ç‰¹åˆ«å…³æ³¨{background}ç›¸å…³çš„å®é™…å½±å“ã€‚"
    
    elif any(keyword in question_lower for keyword in ['ç»éªŒ', 'ç»å†', 'é‡åˆ°', 'ä½“éªŒ', 'æ„Ÿå—']):
        if total_activity > 0:
            return f"åœ¨å¹³å°ä¸Šçš„{total_activity}æ¬¡äº’åŠ¨ä¸­ï¼Œæˆ‘å­¦åˆ°äº†å¾ˆå¤šã€‚{background}çš„èƒŒæ™¯è®©æˆ‘å¯¹è¿™äº›è¯é¢˜æœ‰ç‹¬ç‰¹çš„ç†è§£ã€‚æˆ‘è§‰å¾—è¿™ä¸ªå¹³å°å¾ˆæœ‰ä»·å€¼ï¼Œèƒ½æ¥è§¦åˆ°ä¸åŒçš„è§‚ç‚¹ã€‚"
        else:
            return f"æˆ‘åˆšå¼€å§‹ä½¿ç”¨å¹³å°ï¼Œè¿˜åœ¨ç§¯ç´¯ç»éªŒã€‚æˆ‘çš„{background}èƒŒæ™¯è®©æˆ‘å¯¹æŸäº›è¯é¢˜ç‰¹åˆ«æ„Ÿå…´è¶£ï¼ŒæœŸå¾…æœªæ¥æœ‰æ›´å¤šäº¤æµã€‚"
    
    elif any(keyword in question_lower for keyword in ['å»ºè®®', 'æ¨è', 'åº”è¯¥', 'æ€ä¹ˆåš', 'å¦‚ä½•']):
        return f"åŸºäºæˆ‘ä½œä¸º{profession}çš„ç»éªŒå’Œ{background}çš„èƒŒæ™¯ï¼Œæˆ‘å»ºè®®å¯ä»¥ä»å®é™…æƒ…å†µå‡ºå‘ã€‚ä¿æŒå¼€æ”¾çš„å¿ƒæ€å¾ˆé‡è¦ï¼ŒåŒæ—¶ä¹Ÿè¦æœ‰è‡ªå·±çš„åˆ¤æ–­ã€‚"
    
    else:
        return f"ä½œä¸ºä¸€ä¸ª{activity_level}çš„ç”¨æˆ·ï¼ˆå‘å¸ƒ{len(user_posts)}ç¯‡å†…å®¹ï¼Œ{len(user_comments)}æ¡è¯„è®ºï¼‰ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªé—®é¢˜å¾ˆæœ‰æ„æ€ã€‚æˆ‘ä¼šç»§ç»­å…³æ³¨ç›¸å…³è®¨è®ºã€‚æˆ‘çš„{profession}èƒŒæ™¯è®©æˆ‘å¯¹æ­¤æœ‰ä¸€äº›ç‹¬ç‰¹çš„çœ‹æ³•ã€‚"


@app.route('/api/interview/users/<db_name>', methods=['GET'])
def get_all_users_for_interview(db_name):
    """è·å–æ‰€æœ‰ç”¨æˆ·ç”¨äºé‡‡è®¿ï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT user_id, persona, creation_time, influence_score, follower_count
            FROM users
            ORDER BY influence_score DESC
        """)
        
        users = []
        for row in cursor.fetchall():
            users.append({
                'user_id': row[0],
                'persona': row[1],
                'creation_time': row[2],
                'influence_score': row[3] or 0,
                'follower_count': row[4] or 0
            })
        
        conn.close()
        return jsonify({'users': users})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/interview/posts-with-users/<db_name>', methods=['GET'])
def get_posts_with_users(db_name):
    """è·å–å¸–å­åŠå…¶äº’åŠ¨ç”¨æˆ·ï¼Œç”¨äºé‡‡è®¿å¯¹è±¡é€‰æ‹©ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        # è·å–åˆ†é¡µå‚æ•°
        page = int(request.args.get('page', 1))
        page_size = int(request.args.get('page_size', 10))
        offset = (page - 1) * page_size
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–å¸–å­æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM posts")
        total_posts = cursor.fetchone()[0]
        
        # è·å–å½“å‰é¡µçš„å¸–å­ï¼ˆæŒ‰äº’åŠ¨é‡æ’åºï¼‰
        cursor.execute("""
            SELECT post_id, author_id, content, num_likes, num_comments,
                   (num_likes + num_comments) as total_engagement
            FROM posts
            ORDER BY total_engagement DESC, created_at DESC
            LIMIT ? OFFSET ?
        """, (page_size, offset))
        
        posts = []
        all_interacted_user_ids = set()
        
        for row in cursor.fetchall():
            post_id = row[0]
            post_data = {
                'post_id': post_id,
                'author_id': row[1],
                'content': row[2],  # å®Œæ•´å†…å®¹
                'num_likes': row[3] or 0,
                'num_comments': row[4] or 0,
                'total_engagement': row[5] or 0,
                'interacted_users': []
            }
            
            # è·å–è¯¥å¸–å­çš„äº’åŠ¨ç”¨æˆ·ï¼ˆè¯„è®ºè€…å’Œç‚¹èµè€…ï¼‰
            interacted_users = set()
            
            # è·å–è¯„è®ºè€…
            cursor.execute("""
                SELECT DISTINCT c.author_id
                FROM comments c
                WHERE c.post_id = ?
            """, (post_id,))
            for comment_row in cursor.fetchall():
                interacted_users.add(comment_row[0])
            
            # è·å–ç‚¹èµè€…
            cursor.execute("""
                SELECT DISTINCT user_id
                FROM user_actions
                WHERE action_type IN ('like_post', 'like') AND target_id = ?
            """, (post_id,))
            for like_row in cursor.fetchall():
                interacted_users.add(like_row[0])
            
            # è·å–è¿™äº›ç”¨æˆ·çš„è¯¦ç»†ä¿¡æ¯
            if interacted_users:
                placeholders = ','.join('?' * len(interacted_users))
                cursor.execute(f"""
                    SELECT user_id, persona, influence_score, follower_count
                    FROM users
                    WHERE user_id IN ({placeholders})
                    ORDER BY influence_score DESC
                """, list(interacted_users))
                
                for user_row in cursor.fetchall():
                    post_data['interacted_users'].append({
                        'user_id': user_row[0],
                        'persona': user_row[1],
                        'influence_score': user_row[2] or 0,
                        'follower_count': user_row[3] or 0
                    })
                    all_interacted_user_ids.add(user_row[0])
            
            posts.append(post_data)
        
        # åªåœ¨ç¬¬ä¸€é¡µæ—¶è·å–å…¶ä»–ç”¨æˆ·
        other_users = []
        if page == 1:
            cursor.execute("SELECT user_id, persona, influence_score, follower_count FROM users LIMIT 100")
            all_users = cursor.fetchall()
            
            for user_row in all_users:
                if user_row[0] not in all_interacted_user_ids:
                    other_users.append({
                        'user_id': user_row[0],
                        'persona': user_row[1],
                        'influence_score': user_row[2] or 0,
                        'follower_count': user_row[3] or 0
                    })
        
        # è®¡ç®—æ€»çš„å”¯ä¸€ç”¨æˆ·æ•°
        cursor.execute("SELECT COUNT(DISTINCT user_id) FROM users")
        total_unique_users = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'posts': posts,
            'other_users': other_users,
            'total_posts': total_posts,
            'current_page': page,
            'page_size': page_size,
            'total_pages': (total_posts + page_size - 1) // page_size,
            'total_unique_users': total_unique_users
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500
        
        posts = []
        all_interacted_user_ids = set()
        
        for row in cursor.fetchall():
            post_id = row[0]
            post_data = {
                'post_id': post_id,
                'author_id': row[1],
                'content': row[2],  # å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                'num_likes': row[3] or 0,
                'num_comments': row[4] or 0,
                'total_engagement': row[5] or 0,
                'interacted_users': []
            }
            
            # è·å–è¯¥å¸–å­çš„äº’åŠ¨ç”¨æˆ·ï¼ˆè¯„è®ºè€…å’Œç‚¹èµè€…ï¼‰
            interacted_users = {}  # user_id -> {user_info, interaction_types}
            
            # è·å–è¯„è®ºè€…
            cursor.execute("""
                SELECT DISTINCT c.author_id
                FROM comments c
                WHERE c.post_id = ?
            """, (post_id,))
            for comment_row in cursor.fetchall():
                user_id = comment_row[0]
                if user_id not in interacted_users:
                    interacted_users[user_id] = {'types': []}
                interacted_users[user_id]['types'].append('comment')
            
            # è·å–ç‚¹èµè€…
            cursor.execute("""
                SELECT DISTINCT user_id
                FROM user_actions
                WHERE action_type IN ('like_post', 'like') AND target_id = ?
            """, (post_id,))
            for like_row in cursor.fetchall():
                user_id = like_row[0]
                if user_id not in interacted_users:
                    interacted_users[user_id] = {'types': []}
                interacted_users[user_id]['types'].append('like')
            
            # è·å–è¿™äº›ç”¨æˆ·çš„è¯¦ç»†ä¿¡æ¯
            if interacted_users:
                placeholders = ','.join('?' * len(interacted_users))
                cursor.execute(f"""
                    SELECT user_id, persona, influence_score, follower_count
                    FROM users
                    WHERE user_id IN ({placeholders})
                    ORDER BY influence_score DESC
                """, list(interacted_users.keys()))
                
                for user_row in cursor.fetchall():
                    user_id = user_row[0]
                    post_data['interacted_users'].append({
                        'user_id': user_id,
                        'persona': user_row[1],
                        'influence_score': user_row[2] or 0,
                        'follower_count': user_row[3] or 0,
                        'interaction_type': interacted_users[user_id]['types']
                    })
                    all_interacted_user_ids.add(user_id)
            
            posts.append(post_data)
        
        # è·å–æ²¡æœ‰äº’åŠ¨çš„å…¶ä»–ç”¨æˆ·
        cursor.execute("SELECT user_id, persona, influence_score, follower_count FROM users")
        all_users = cursor.fetchall()
        
        other_users = []
        for user_row in all_users:
            if user_row[0] not in all_interacted_user_ids:
                other_users.append({
                    'user_id': user_row[0],
                    'persona': user_row[1],
                    'influence_score': user_row[2] or 0,
                    'follower_count': user_row[3] or 0
                })
        
        # æŒ‰å½±å“åŠ›æ’åºå…¶ä»–ç”¨æˆ·
        other_users.sort(key=lambda x: x['influence_score'], reverse=True)
        
        conn.close()
        
        return jsonify({
            'posts': posts,
            'other_users': other_users,
            'summary': {
                'total_posts': len(posts),
                'total_interacted_users': len(all_interacted_user_ids),
                'total_other_users': len(other_users),
                'total_users': len(all_interacted_user_ids) + len(other_users)
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500
        # è·å–æ²¡æœ‰äº’åŠ¨çš„å…¶ä»–ç”¨æˆ·
        cursor.execute("SELECT user_id, persona, influence_score, follower_count FROM users")
        all_users = cursor.fetchall()
        
        other_users = []
        for user_row in all_users:
            if user_row[0] not in all_interacted_user_ids:
                other_users.append({
                    'user_id': user_row[0],
                    'persona': user_row[1],
                    'influence_score': user_row[2] or 0,
                    'follower_count': user_row[3] or 0
                })
        
        # æŒ‰å½±å“åŠ›æ’åºå…¶ä»–ç”¨æˆ·
        other_users.sort(key=lambda x: x['influence_score'], reverse=True)
        
        conn.close()
        
        return jsonify({
            'posts': posts,
            'other_users': other_users,
            'summary': {
                'total_posts': len(posts),
                'total_interacted_users': len(all_interacted_user_ids),
                'total_other_users': len(other_users),
                'total_users': len(all_interacted_user_ids) + len(other_users)
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/interview/all-user-ids/<db_name>', methods=['GET'])
def get_all_user_ids(db_name):
    """è·å–æ‰€æœ‰ç”¨æˆ·IDï¼Œç”¨äºå…¨é€‰åŠŸèƒ½"""
    try:
        db_path = os.path.join(DATABASE_DIR, db_name)
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT user_id FROM users")
        user_ids = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        
        return jsonify({
            'user_ids': user_ids,
            'total': len(user_ids)
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/opinion-balance/logs/stream', methods=['GET'])
def stream_opinion_balance_logs():
    """
    Stream the latest opinion balance log file using SSE (Server-Sent Events).

    Query params:
      - tail: number of last lines to emit first (default 300, max 2000)
      - follow_latest: whether to switch to a newer log file if it appears (default true)
    """
    from flask import Response, stream_with_context
    from log_tail import find_latest_file, tail_lines

    # source=workflow streams from logs/workflow (preferred for real-time UI);
    # source=opinion_balance streams from logs/opinion_balance (legacy).
    source = request.args.get('source', default='workflow')
    source = str(source).lower().strip()

    if source == 'opinion_balance':
        base_dir = OPINION_BALANCE_LOG_DIR
    else:
        base_dir = WORKFLOW_LOG_DIR

    tail = request.args.get('tail', default=0, type=int)
    tail = max(0, min(2000, tail))

    follow_latest = request.args.get('follow_latest', default='true')
    follow_latest = str(follow_latest).lower() not in ('0', 'false', 'no', 'off')

    poll_interval_sec = 0.25
    heartbeat_sec = 15.0

    def sse_data(line: str) -> str:
        safe = (line or '').replace('\r', '').rstrip('\n')
        return f"data: {safe}\n\n"

    def generate():
        os.makedirs(base_dir, exist_ok=True)

        current_path = find_latest_file(base_dir, pattern="*.log")
        if not current_path:
            # Don't silently fail: provide a visible error line to the UI.
            yield sse_data(f"ERROR: no log file found under {os.path.relpath(base_dir, os.path.dirname(__file__))} (start the workflow first)")
            return

        yield sse_data(f"INFO: connected to {os.path.basename(current_path)}")

        if tail > 0:
            try:
                for line in tail_lines(current_path, n=tail):
                    yield sse_data(line)
            except Exception as e:
                yield sse_data(f"ERROR: failed to read log tail: {e}")

        last_switch_check = time.time()
        last_heartbeat = time.time()

        # Tail-follow the active log file.
        try:
            f = open(current_path, 'r', encoding='utf-8', errors='replace')
            f.seek(0, os.SEEK_END)

            while True:
                line = f.readline()
                if line:
                    yield sse_data(line)
                    continue

                now = time.time()
                if now - last_heartbeat >= heartbeat_sec:
                    last_heartbeat = now
                    yield ": keep-alive\n\n"

                if follow_latest and (now - last_switch_check >= 2.0):
                    last_switch_check = now
                    latest = find_latest_file(base_dir, pattern="*.log")
                    if latest and latest != current_path:
                        current_path = latest
                        try:
                            f.close()
                        except Exception:
                            pass
                        f = open(current_path, 'r', encoding='utf-8', errors='replace')
                        # New run files are typically small; stream from the beginning.
                        yield sse_data(f"INFO: switched to new log file: {os.path.basename(current_path)}")
                        continue

                time.sleep(poll_interval_sec)
        except GeneratorExit:
            return
        except Exception as e:
            yield sse_data(f"ERROR: log stream stopped unexpectedly: {e}")
        finally:
            try:
                f.close()
            except Exception:
                pass

    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


@app.route('/api/dynamic/start', methods=['POST'])
def start_dynamic_demo():
    """å¯åŠ¨åŠ¨æ€æ¼”ç¤ºç³»ç»Ÿï¼ˆæ•°æ®åº“ + ä¸»ç¨‹åºï¼‰
    
    è‡ªåŠ¨ä½¿ç”¨å½“å‰ Python ç¯å¢ƒï¼ˆfrontend_api.py è¿è¡Œçš„ç¯å¢ƒï¼‰
    
    è¯·æ±‚ä½“:
        {
            "conda_env": "ç¯å¢ƒåç§°"  // å¯é€‰ï¼Œå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§
        }
    
    å“åº”:
        {
            "success": true/false,
            "message": "æ¶ˆæ¯",
            "processes": {
                "database": {"pid": 12345, "status": "running"},
                "main": {"pid": 12346, "status": "running"}
            }
        }
    """
    try:
        # è§£æè¯·æ±‚ä½“ï¼ˆä¿ç•™ conda_env å‚æ•°å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨ï¼‰
        data = request.get_json() or {}
        conda_env = data.get('conda_env')  # ä¿ç•™å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨
        
        # è°ƒç”¨ process_manager.start_demo()
        result = process_manager.start_demo(conda_env=conda_env)
        
        # è¿”å› JSON å“åº”
        return jsonify(result)
        
    except Exception as e:
        # å¤„ç†å¼‚å¸¸å¹¶è¿”å›é”™è¯¯å“åº”
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Failed to start dynamic demo: {str(e)}',
            'error': 'UnexpectedError'
        }), 500


@app.route('/api/dynamic/stop', methods=['POST'])
def stop_dynamic_demo():
    """åœæ­¢æ‰€æœ‰åŠ¨æ€æ¼”ç¤ºè¿›ç¨‹
    
    å“åº”:
        {
            "success": true/false,
            "message": "æ¶ˆæ¯",
            "stopped_processes": ["database", "main", "opinion_balance"],
            "errors": []
        }
    """
    try:
        # è°ƒç”¨ process_manager.stop_all_processes()
        result = process_manager.stop_all_processes()
        
        # è¿”å› JSON å“åº”
        return jsonify(result)
        
    except Exception as e:
        # å¤„ç†å¼‚å¸¸å¹¶è¿”å›é”™è¯¯å“åº”
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Failed to stop processes: {str(e)}',
            'error': 'UnexpectedError',
            'stopped_processes': [],
            'errors': [str(e)]
        }), 500


@app.route('/api/dynamic/opinion-balance/start', methods=['POST'])
def start_opinion_balance_system():
    """å¯åŠ¨èˆ†è®ºå¹³è¡¡ç³»ç»Ÿ
    
    è‡ªåŠ¨ä½¿ç”¨å½“å‰ Python ç¯å¢ƒ
    
    è¯·æ±‚ä½“:
        {
            "conda_env": "ç¯å¢ƒåç§°"  // å¯é€‰ï¼Œå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§
        }
    
    å“åº”:
        {
            "success": true/false,
            "message": "æ¶ˆæ¯",
            "process": {
                "pid": 12347,
                "status": "running"
            }
        }
    """
    try:
        # è§£æè¯·æ±‚ä½“ï¼ˆä¿ç•™ conda_env å‚æ•°å…¼å®¹æ€§ï¼‰
        data = request.get_json() or {}
        conda_env = data.get('conda_env')  # ä¿ç•™å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨
        
        # è°ƒç”¨ process_manager.start_opinion_balance()
        result = process_manager.start_opinion_balance(conda_env=conda_env)
        
        # è¿”å› JSON å“åº”
        return jsonify(result)
        
    except Exception as e:
        # å¤„ç†å¼‚å¸¸å¹¶è¿”å›é”™è¯¯å“åº”
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Failed to start opinion balance: {str(e)}',
            'error': 'UnexpectedError'
        }), 500


@app.route('/api/dynamic/opinion-balance/stop', methods=['POST'])
def stop_opinion_balance_system():
    """åœæ­¢èˆ†è®ºå¹³è¡¡ç³»ç»Ÿ
    
    å“åº”:
        {
            "success": true/false,
            "message": "æ¶ˆæ¯",
            "process": "opinion_balance"
        }
    """
    try:
        # è°ƒç”¨ process_manager.stop_process('opinion_balance')
        result = process_manager.stop_process('opinion_balance')
        
        # è¿”å› JSON å“åº”
        return jsonify(result)
        
    except Exception as e:
        # å¤„ç†å¼‚å¸¸å¹¶è¿”å›é”™è¯¯å“åº”
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'Failed to stop opinion balance: {str(e)}',
            'error': 'UnexpectedError'
        }), 500


@app.route('/api/dynamic/status', methods=['GET'])
def get_dynamic_demo_status():
    """è·å–åŠ¨æ€æ¼”ç¤ºç³»ç»ŸçŠ¶æ€
    
    å“åº”:
        {
            "database": {
                "status": "running/stopped",
                "pid": 12345,
                "uptime": 120
            },
            "main": {
                "status": "running/stopped",
                "pid": 12346,
                "uptime": 115
            },
            "opinion_balance": {
                "status": "stopped",
                "pid": null,
                "uptime": 0
            }
        }
    """
    try:
        # è°ƒç”¨ process_manager.get_process_status()
        result = process_manager.get_process_status()
        
        # è¿”å› JSON å“åº”
        return jsonify(result)
        
    except Exception as e:
        # å¤„ç†å¼‚å¸¸å¹¶è¿”å›é”™è¯¯å“åº”
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': str(e),
            'database': {'status': 'unknown', 'pid': None, 'uptime': 0},
            'main': {'status': 'unknown', 'pid': None, 'uptime': 0},
            'opinion_balance': {'status': 'unknown', 'pid': None, 'uptime': 0}
        }), 500





# ============================================================================
# å¸–å­çƒ­åº¦æ¦œåŠŸèƒ½
# ============================================================================

class HeatScoreCalculator:
    """çƒ­åº¦è¯„åˆ†è®¡ç®—å™¨ - ä¸ agent_user.py çš„ get_feed() è¯„åˆ†ç®—æ³•å®Œå…¨ä¸€è‡´
    
    è¯¥ç±»è´Ÿè´£è®¡ç®—å¸–å­çš„çƒ­åº¦è¯„åˆ†ï¼Œä½¿ç”¨ä¸ agent_user.py ä¸­ get_feed() å‡½æ•°
    å®Œå…¨ç›¸åŒçš„ç®—æ³•å’Œå‚æ•°ï¼Œç¡®ä¿å‰åç«¯æ•°æ®çš„ä¸€è‡´æ€§ã€‚
    
    è¯„åˆ†å…¬å¼ï¼š
        score = (engagement + BETA_BIAS) Ã— freshness
        engagement = num_comments + num_shares + num_likes
        freshness = max(MIN_FRESHNESS, 1.0 - LAMBDA_DECAY Ã— age)
        age = max(0, current_time_step - post_time_step)
    """
    
    # å›ºå®šå‚æ•°ï¼ˆä¸ agent_user.py ä¿æŒä¸€è‡´ï¼‰
    LAMBDA_DECAY = 0.1      # æ—¶é—´è¡°å‡ç³»æ•°
    BETA_BIAS = 180         # åŸºç¡€åç½®å€¼
    MIN_FRESHNESS = 0.1     # æœ€å°æ–°é²œåº¦
    
    def __init__(self, db_path: str):
        """åˆå§‹åŒ–çƒ­åº¦è¯„åˆ†è®¡ç®—å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path
    
    def get_current_time_step(self) -> int:
        """è·å–å½“å‰æ—¶é—´æ­¥
        
        ä» post_timesteps è¡¨è·å–æœ€å¤§ time_step å€¼ä½œä¸ºå½“å‰æ—¶é—´æ­¥ã€‚
        å¦‚æœè¡¨ä¸ºç©ºæˆ–æŸ¥è¯¢å¤±è´¥ï¼Œè¿”å› 0ã€‚
        
        Returns:
            int: å½“å‰æ—¶é—´æ­¥ï¼Œå¦‚æœè¡¨ä¸ºç©ºåˆ™è¿”å› 0
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('SELECT COALESCE(MAX(time_step), 0) FROM post_timesteps')
            result = cursor.fetchone()
            current_step = result[0] if result else 0
            
            conn.close()
            return current_step
        except Exception as e:
            print(f'âš ï¸ è·å–å½“å‰æ—¶é—´æ­¥å¤±è´¥: {e}')
            return 0
    
    def get_post_time_step(self, post_id: str) -> Optional[int]:
        """è·å–å¸–å­çš„åˆ›å»ºæ—¶é—´æ­¥
        
        Args:
            post_id: å¸–å­ID
            
        Returns:
            Optional[int]: æ—¶é—´æ­¥ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('SELECT time_step FROM post_timesteps WHERE post_id = ?', (post_id,))
            result = cursor.fetchone()
            
            conn.close()
            return result[0] if result else None
        except Exception as e:
            print(f'âš ï¸ è·å–å¸–å­æ—¶é—´æ­¥å¤±è´¥ (post_id={post_id}): {e}')
            return None
    
    def calculate_score(self, post: dict, current_time_step: int) -> float:
        """è®¡ç®—å•ä¸ªå¸–å­çš„çƒ­åº¦è¯„åˆ†
        
        ä½¿ç”¨ä¸ agent_user.py å®Œå…¨ä¸€è‡´çš„è¯„åˆ†å…¬å¼ï¼š
        1. è®¡ç®—äº’åŠ¨æ•°ï¼šengagement = num_comments + num_shares + num_likes
        2. è®¡ç®—å¹´é¾„ï¼šage = max(0, current_time_step - post_time_step)
           å¦‚æœ post_time_step ä¸å­˜åœ¨ï¼Œåˆ™ age = 0
        3. è®¡ç®—æ–°é²œåº¦ï¼šfreshness = max(0.1, 1.0 - 0.1 Ã— age)
        4. è®¡ç®—è¯„åˆ†ï¼šscore = (engagement + 180) Ã— freshness
        
        Args:
            post: å¸–å­æ•°æ®å­—å…¸ï¼Œå¿…é¡»åŒ…å«ï¼š
                  - post_id: å¸–å­ID
                  - num_comments: è¯„è®ºæ•°
                  - num_shares: åˆ†äº«æ•°
                  - num_likes: ç‚¹èµæ•°
            current_time_step: å½“å‰æ—¶é—´æ­¥
            
        Returns:
            float: çƒ­åº¦è¯„åˆ†
        """
        # è®¡ç®—äº’åŠ¨æ•°ï¼ˆä¸ agent_user.py ä¿æŒä¸€è‡´ï¼‰
        engagement = (
            (post.get('num_comments') or 0) +
            (post.get('num_shares') or 0) +
            (post.get('num_likes') or 0)
        )
        
        # è·å–å¸–å­çš„åˆ›å»ºæ—¶é—´æ­¥
        post_time_step = self.get_post_time_step(post['post_id'])
        
        # è®¡ç®—å¹´é¾„ï¼ˆå¦‚æœ post_time_step ä¸º Noneï¼Œåˆ™ age = 0ï¼‰
        if post_time_step is not None:
            age = max(0, current_time_step - post_time_step)
        else:
            age = 0
        
        # è®¡ç®—æ–°é²œåº¦
        freshness = max(self.MIN_FRESHNESS, 1.0 - self.LAMBDA_DECAY * age)
        
        # è®¡ç®—æœ€ç»ˆè¯„åˆ†
        score = (engagement + self.BETA_BIAS) * freshness
        
        return score
    
    @staticmethod
    def calculate_fingerprint(items: List[dict]) -> str:
        """è®¡ç®—æ¦œå•æŒ‡çº¹ï¼Œç”¨äºå»é‡
        
        åŸºäºæ¦œå•ä¸­æ‰€æœ‰å¸–å­çš„å…³é”®å­—æ®µï¼ˆpostId, score, createdAtï¼‰è®¡ç®— MD5 å“ˆå¸Œå€¼ï¼Œ
        ç”¨äºåˆ¤æ–­æ¦œå•æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œé¿å…æ— æ•ˆçš„ SSE æ¨é€ã€‚
        
        Args:
            items: æ¦œå•é¡¹åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« postId, score, createdAt å­—æ®µ
            
        Returns:
            str: MD5 å“ˆå¸Œå€¼ï¼ˆ32ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        """
        import hashlib
        import json
        
        # æå–å…³é”®å­—æ®µï¼špostId, score, createdAt
        key_data = [
            (item['postId'], item['score'], item['createdAt'])
            for item in items
        ]
        
        # åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼ˆç¡®ä¿é”®æ’åºä»¥ä¿è¯ä¸€è‡´æ€§ï¼‰
        json_str = json.dumps(key_data, sort_keys=True)
        
        # è®¡ç®— MD5 å“ˆå¸Œ
        fingerprint = hashlib.md5(json_str.encode()).hexdigest()
        
        return fingerprint


# ============================================================================
# å¸–å­çƒ­åº¦æ¦œ API
# ============================================================================

@app.route('/api/leaderboard', methods=['GET'])
def get_leaderboard():
    """è·å–çƒ­åº¦æ’è¡Œæ¦œ
    
    æŸ¥è¯¢æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å¸–å­ï¼Œè®¡ç®—çƒ­åº¦è¯„åˆ†ï¼Œè¿”å› Top N ä¸ªå¸–å­ã€‚
    
    æŸ¥è¯¢å‚æ•°:
        limit: è¿”å›æ•°é‡ï¼Œé»˜è®¤ 20ï¼Œæœ€å¤§ 100
        
    è¿”å›:
        {
            "items": [
                {
                    "postId": str,
                    "excerpt": str,  # ä¼˜å…ˆä½¿ç”¨ summaryï¼Œå¦åˆ™æˆªæ–­ content å‰ 100 å­—ç¬¦
                    "score": float,
                    "authorId": str,
                    "createdAt": str,  # ISO 8601 æ ¼å¼
                    "likeCount": int,
                    "shareCount": int,
                    "commentCount": int
                },
                ...
            ],
            "timeStep": int,
            "fingerprint": str  # ç”¨äºå»é‡çš„å“ˆå¸Œå€¼
        }
    """
    try:
        # è·å– limit å‚æ•°ï¼ˆé»˜è®¤ 20ï¼Œæœ€å¤§ 100ï¼‰
        limit = request.args.get('limit', default=20, type=int)
        limit = min(max(1, limit), 100)  # é™åˆ¶åœ¨ 1-100 èŒƒå›´å†…
        
        # è·å–æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨ simulation.dbï¼‰
        db_name = request.args.get('db', default='simulation.db', type=str)
        db_path = os.path.join(DATABASE_DIR, db_name)
        
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        # åˆ›å»ºçƒ­åº¦è¯„åˆ†è®¡ç®—å™¨
        calculator = HeatScoreCalculator(db_path)
        
        # è·å–å½“å‰æ—¶é—´æ­¥
        current_time_step = calculator.get_current_time_step()
        
        # æŸ¥è¯¢æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å¸–å­
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # åªæŸ¥è¯¢å¿…éœ€å­—æ®µï¼Œè¿‡æ»¤æ¡ä»¶ï¼šstatus IS NULL OR status != 'taken_down'
        cursor.execute("""
            SELECT 
                post_id,
                summary,
                content,
                author_id,
                created_at,
                num_likes,
                num_shares,
                num_comments
            FROM posts
            WHERE status IS NULL OR status != 'taken_down'
        """)
        
        # è®¡ç®—æ¯ä¸ªå¸–å­çš„çƒ­åº¦è¯„åˆ†
        posts_with_scores = []
        for row in cursor.fetchall():
            post = {
                'post_id': row[0],
                'summary': row[1],
                'content': row[2],
                'author_id': row[3],
                'created_at': row[4],
                'num_likes': row[5] or 0,
                'num_shares': row[6] or 0,
                'num_comments': row[7] or 0
            }
            
            # è®¡ç®—çƒ­åº¦è¯„åˆ†
            score = calculator.calculate_score(post, current_time_step)
            
            # å¤„ç† excerpt å­—æ®µï¼ˆä¼˜å…ˆä½¿ç”¨ summaryï¼Œå¦åˆ™æˆªæ–­ contentï¼‰
            if post['summary']:
                excerpt = post['summary']
            else:
                content = post['content'] or ''
                excerpt = content[:100] + ('...' if len(content) > 100 else '')
            
            posts_with_scores.append({
                'postId': post['post_id'],
                'excerpt': excerpt,
                'score': score,
                'authorId': post['author_id'],
                'createdAt': post['created_at'],
                'likeCount': post['num_likes'],
                'shareCount': post['num_shares'],
                'commentCount': post['num_comments']
            })
        
        conn.close()
        
        # æ’åºï¼šä¸»æ’åº score é™åºï¼Œæ¬¡æ’åº createdAt é™åºï¼Œä¸‰çº§æ’åº postId å‡åº
        # ä½¿ç”¨ç¨³å®šæ’åºçš„ç‰¹æ€§ï¼Œä»æœ€ä½ä¼˜å…ˆçº§åˆ°æœ€é«˜ä¼˜å…ˆçº§ä¾æ¬¡æ’åº
        
        # ç¬¬ä¸€æ­¥ï¼šæŒ‰ postId å‡åºæ’åºï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
        posts_with_scores.sort(key=lambda x: x['postId'])
        
        # ç¬¬äºŒæ­¥ï¼šæŒ‰ createdAt é™åºæ’åºï¼ˆæ¬¡ä¼˜å…ˆçº§ï¼Œç¨³å®šæ’åºä¿æŒ postId é¡ºåºï¼‰
        posts_with_scores.sort(key=lambda x: x['createdAt'] or '', reverse=True)
        
        # ç¬¬ä¸‰æ­¥ï¼šæŒ‰ score é™åºæ’åºï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç¨³å®šæ’åºä¿æŒå‰ä¸¤çº§é¡ºåºï¼‰
        posts_with_scores.sort(key=lambda x: x['score'], reverse=True)
        
        # è¿”å›å‰ N ä¸ªç»“æœ
        top_posts = posts_with_scores[:limit]
        
        # è®¡ç®— fingerprint
        fingerprint = HeatScoreCalculator.calculate_fingerprint(top_posts)
        
        return jsonify({
            'items': top_posts,
            'timeStep': current_time_step,
            'fingerprint': fingerprint
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/leaderboard/posts/<post_id>', methods=['GET'])
def get_post_detail_by_id(post_id: str):
    """è·å–å¸–å­è¯¦æƒ…ï¼ˆçƒ­åº¦æ¦œä¸“ç”¨ï¼‰
    
    æŸ¥è¯¢æŒ‡å®š post_id çš„å¸–å­ï¼Œè¿”å›å®Œæ•´çš„å¸–å­ä¿¡æ¯ã€‚
    
    è·¯å¾„å‚æ•°:
        post_id: å¸–å­ID
        
    æŸ¥è¯¢å‚æ•°:
        db: æ•°æ®åº“åç§°ï¼ˆé»˜è®¤ simulation.dbï¼‰
        
    è¿”å›:
        {
            "postId": str,
            "content": str,
            "excerpt": str,  # summary å­—æ®µ
            "authorId": str,
            "createdAt": str,  # ISO 8601 æ ¼å¼
            "likeCount": int,
            "shareCount": int,
            "commentCount": int
        }
        
    é”™è¯¯:
        404: å¸–å­ä¸å­˜åœ¨æˆ–å·²åˆ é™¤ï¼ˆstatus = 'taken_down'ï¼‰
    """
    try:
        # è·å–æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨ simulation.dbï¼‰
        db_name = request.args.get('db', default='simulation.db', type=str)
        db_path = os.path.join(DATABASE_DIR, db_name)
        
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        # æŸ¥è¯¢å¸–å­
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è¿‡æ»¤æ¡ä»¶ï¼šstatus IS NULL OR status != 'taken_down'
        cursor.execute("""
            SELECT 
                post_id,
                content,
                summary,
                author_id,
                created_at,
                num_likes,
                num_shares,
                num_comments
            FROM posts
            WHERE post_id = ? AND (status IS NULL OR status != 'taken_down')
        """, (post_id,))
        
        row = cursor.fetchone()
        conn.close()
        
        # å¦‚æœå¸–å­ä¸å­˜åœ¨æˆ–å·²åˆ é™¤ï¼Œè¿”å› 404
        if not row:
            return jsonify({'error': 'Post not found'}), 404
        
        # æ„é€ å“åº”æ•°æ®ï¼ˆè½¬æ¢ä¸º camelCaseï¼‰
        response = {
            'postId': row[0],
            'content': row[1] or '',
            'excerpt': row[2] or '',  # summary å­—æ®µ
            'authorId': row[3],
            'createdAt': row[4],
            'likeCount': row[5] or 0,
            'shareCount': row[6] or 0,
            'commentCount': row[7] or 0
        }
        
        return jsonify(response)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/leaderboard/posts/<post_id>/comments', methods=['GET'])
def get_post_comments_by_id(post_id: str):
    """è·å–å¸–å­è¯„è®ºåˆ—è¡¨ï¼ˆçƒ­åº¦æ¦œä¸“ç”¨ï¼‰
    
    æŸ¥è¯¢æŒ‡å®š post_id çš„æ‰€æœ‰è¯„è®ºï¼Œæ”¯æŒæŒ‰ç‚¹èµæ•°æˆ–æ—¶é—´æ’åºã€‚
    
    è·¯å¾„å‚æ•°:
        post_id: å¸–å­ID
        
    æŸ¥è¯¢å‚æ•°:
        sort: æ’åºæ–¹å¼ï¼Œ'likes' æˆ– 'time'ï¼Œé»˜è®¤ 'likes'
        limit: è¿”å›æ•°é‡ï¼Œé»˜è®¤ 100
        db: æ•°æ®åº“åç§°ï¼ˆé»˜è®¤ simulation.dbï¼‰
        
    è¿”å›:
        {
            "comments": [
                {
                    "commentId": str,
                    "content": str,
                    "authorId": str,
                    "createdAt": str,  # ISO 8601 æ ¼å¼
                    "likeCount": int
                },
                ...
            ]
        }
        
    é”™è¯¯:
        400: æ— æ•ˆçš„ sort å‚æ•°
    """
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        sort_param = request.args.get('sort', default='likes', type=str).lower()
        limit = request.args.get('limit', default=100, type=int)
        db_name = request.args.get('db', default='simulation.db', type=str)
        
        # éªŒè¯ sort å‚æ•°
        if sort_param not in ['likes', 'time']:
            return jsonify({'error': 'Invalid sort parameter. Must be "likes" or "time"'}), 400
        
        # é™åˆ¶ limit èŒƒå›´
        limit = min(max(1, limit), 100)
        
        # è·å–æ•°æ®åº“è·¯å¾„
        db_path = os.path.join(DATABASE_DIR, db_name)
        
        if not os.path.exists(db_path):
            return jsonify({'error': 'Database not found'}), 404
        
        # æŸ¥è¯¢è¯„è®º
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æ ¹æ® sort å‚æ•°ç¡®å®šæ’åºæ–¹å¼
        if sort_param == 'likes':
            order_by = 'num_likes DESC, created_at DESC'
        else:  # sort_param == 'time'
            order_by = 'created_at DESC'
        
        # æŸ¥è¯¢è¯„è®ºåˆ—è¡¨
        query = f"""
            SELECT 
                comment_id,
                content,
                author_id,
                created_at,
                num_likes
            FROM comments
            WHERE post_id = ?
            ORDER BY {order_by}
            LIMIT ?
        """
        
        cursor.execute(query, (post_id, limit))
        
        # æ„é€ å“åº”æ•°æ®ï¼ˆè½¬æ¢ä¸º camelCaseï¼‰
        comments = []
        for row in cursor.fetchall():
            comments.append({
                'commentId': row[0],
                'content': row[1] or '',
                'authorId': row[2],
                'createdAt': row[3],
                'likeCount': row[4] or 0
            })
        
        conn.close()
        
        return jsonify({'comments': comments})
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


# ============================================================================
# SSE äº‹ä»¶æµ - å®æ—¶çƒ­åº¦æ¦œæ›´æ–°
# ============================================================================

@app.route('/api/events', methods=['GET'])
def event_stream():
    """SSE äº‹ä»¶æµï¼Œæ¨é€çƒ­åº¦æ¦œæ›´æ–°
    
    å»ºç«‹ Server-Sent Events è¿æ¥ï¼Œæ¯ 1 ç§’æ¨é€ä¸€æ¬¡çƒ­åº¦æ¦œæ›´æ–°ã€‚
    ä½¿ç”¨ fingerprint æœºåˆ¶é¿å…æ— æ•ˆæ¨é€ï¼šåªåœ¨æ¦œå•å†…å®¹å‘ç”Ÿå˜åŒ–æ—¶æ‰æ¨é€æ•°æ®ã€‚
    
    äº‹ä»¶æ ¼å¼:
        event: leaderboard-update
        data: {
            "items": [...],  # ä¸ GET /api/leaderboard è¿”å›æ ¼å¼ä¸€è‡´
            "timeStep": int,
            "fingerprint": str,
            "timestamp": str  # ISO 8601 æ ¼å¼
        }
        
    æ¨é€é—´éš”: 1 ç§’
    æ¨é€ç­–ç•¥: ä»…å½“ fingerprint å˜åŒ–æ—¶æ¨é€ï¼ˆé¿å…æ— æ•ˆæ›´æ–°ï¼‰
    """
    # åœ¨ç”Ÿæˆå™¨å¤–éƒ¨è·å–è¯·æ±‚å‚æ•°ï¼ˆé¿å…ä¸Šä¸‹æ–‡é—®é¢˜ï¼‰
    db_name = request.args.get('db', default='simulation.db', type=str)
    limit = request.args.get('limit', default=20, type=int)
    limit = min(max(1, limit), 100)  # é™åˆ¶åœ¨ 1-100 èŒƒå›´å†…
    
    def generate():
        """ç”Ÿæˆå™¨å‡½æ•°ï¼ŒæŒç»­æ¨é€çƒ­åº¦æ¦œæ›´æ–°"""
        last_fingerprint = None  # è®°å½•ä¸Šæ¬¡çš„ fingerprint
        
        try:
            while True:
                try:
                    # è·å–æ•°æ®åº“è·¯å¾„ï¼ˆä½¿ç”¨å¤–éƒ¨å˜é‡ï¼‰
                    db_path = os.path.join(DATABASE_DIR, db_name)
                    
                    if not os.path.exists(db_path):
                        # æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå‘é€é”™è¯¯äº‹ä»¶
                        yield f'event: error\ndata: {{"error": "Database not found"}}\n\n'
                        break
                    
                    # åˆ›å»ºçƒ­åº¦è¯„åˆ†è®¡ç®—å™¨
                    calculator = HeatScoreCalculator(db_path)
                    
                    # è·å–å½“å‰æ—¶é—´æ­¥
                    current_time_step = calculator.get_current_time_step()
                    
                    # æŸ¥è¯¢æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å¸–å­
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()
                    
                    # åªæŸ¥è¯¢å¿…éœ€å­—æ®µï¼Œè¿‡æ»¤æ¡ä»¶ï¼šstatus IS NULL OR status != 'taken_down'
                    cursor.execute("""
                        SELECT 
                            post_id,
                            summary,
                            content,
                            author_id,
                            created_at,
                            num_likes,
                            num_shares,
                            num_comments
                        FROM posts
                        WHERE status IS NULL OR status != 'taken_down'
                    """)
                    
                    # è®¡ç®—æ¯ä¸ªå¸–å­çš„çƒ­åº¦è¯„åˆ†
                    posts_with_scores = []
                    for row in cursor.fetchall():
                        post = {
                            'post_id': row[0],
                            'summary': row[1],
                            'content': row[2],
                            'author_id': row[3],
                            'created_at': row[4],
                            'num_likes': row[5] or 0,
                            'num_shares': row[6] or 0,
                            'num_comments': row[7] or 0
                        }
                        
                        # è®¡ç®—çƒ­åº¦è¯„åˆ†
                        score = calculator.calculate_score(post, current_time_step)
                        
                        # å¤„ç† excerpt å­—æ®µï¼ˆä¼˜å…ˆä½¿ç”¨ summaryï¼Œå¦åˆ™æˆªæ–­ contentï¼‰
                        if post['summary']:
                            excerpt = post['summary']
                        else:
                            content = post['content'] or ''
                            excerpt = content[:100] + ('...' if len(content) > 100 else '')
                        
                        posts_with_scores.append({
                            'postId': post['post_id'],
                            'excerpt': excerpt,
                            'score': score,
                            'authorId': post['author_id'],
                            'createdAt': post['created_at'],
                            'likeCount': post['num_likes'],
                            'shareCount': post['num_shares'],
                            'commentCount': post['num_comments']
                        })
                    
                    conn.close()
                    
                    # æ’åºï¼šä¸»æ’åº score é™åºï¼Œæ¬¡æ’åº createdAt é™åºï¼Œä¸‰çº§æ’åº postId å‡åº
                    # ä½¿ç”¨ç¨³å®šæ’åºçš„ç‰¹æ€§ï¼Œä»æœ€ä½ä¼˜å…ˆçº§åˆ°æœ€é«˜ä¼˜å…ˆçº§ä¾æ¬¡æ’åº
                    
                    # ç¬¬ä¸€æ­¥ï¼šæŒ‰ postId å‡åºæ’åºï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
                    posts_with_scores.sort(key=lambda x: x['postId'])
                    
                    # ç¬¬äºŒæ­¥ï¼šæŒ‰ createdAt é™åºæ’åºï¼ˆæ¬¡ä¼˜å…ˆçº§ï¼Œç¨³å®šæ’åºä¿æŒ postId é¡ºåºï¼‰
                    posts_with_scores.sort(key=lambda x: x['createdAt'] or '', reverse=True)
                    
                    # ç¬¬ä¸‰æ­¥ï¼šæŒ‰ score é™åºæ’åºï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œç¨³å®šæ’åºä¿æŒå‰ä¸¤çº§é¡ºåºï¼‰
                    posts_with_scores.sort(key=lambda x: x['score'], reverse=True)
                    
                    # è¿”å›å‰ N ä¸ªç»“æœ
                    top_posts = posts_with_scores[:limit]
                    
                    # è®¡ç®— fingerprint
                    current_fingerprint = HeatScoreCalculator.calculate_fingerprint(top_posts)
                    
                    # åªåœ¨ fingerprint å˜åŒ–æ—¶æ¨é€
                    if current_fingerprint != last_fingerprint:
                        # æ„é€ äº‹ä»¶æ•°æ®
                        event_data = {
                            'items': top_posts,
                            'timeStep': current_time_step,
                            'fingerprint': current_fingerprint,
                            'timestamp': datetime.datetime.now().isoformat()
                        }
                        
                        # æ ¼å¼åŒ–ä¸º SSE æ ¼å¼
                        import json
                        data_json = json.dumps(event_data, ensure_ascii=False)
                        yield f'event: leaderboard-update\ndata: {data_json}\n\n'
                        
                        # æ›´æ–° last_fingerprint
                        last_fingerprint = current_fingerprint
                    
                    # ç­‰å¾… 1 ç§’
                    time.sleep(1)
                    
                except GeneratorExit:
                    # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
                    print('âœ… SSE å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ¸…ç†èµ„æº')
                    break
                except Exception as e:
                    # å‘ç”Ÿé”™è¯¯ï¼Œè®°å½•æ—¥å¿—å¹¶å‘é€é”™è¯¯äº‹ä»¶
                    import traceback
                    traceback.print_exc()
                    yield f'event: error\ndata: {{"error": "{str(e)}"}}\n\n'
                    break
                    
        except GeneratorExit:
            # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥
            print('âœ… SSE å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼ˆå¤–å±‚ï¼‰ï¼Œæ¸…ç†èµ„æº')
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯ï¼Œè®°å½•æ—¥å¿—
            import traceback
            traceback.print_exc()
    
    # è¿”å›æµå¼å“åº”
    from flask import Response
    return Response(
        generate(),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no',  # ç¦ç”¨ nginx ç¼“å†²
            'Connection': 'keep-alive'
        }
    )


if __name__ == '__main__':
    print("Starting EvoCorps Frontend API Server...")
    print("Database directory:", os.path.abspath(DATABASE_DIR))
    print("Server running at: http://127.0.0.1:5001")
    print("Press Ctrl+C to stop")
    app.run(host='127.0.0.1', port=5001, debug=False, use_reloader=False)